digraph {
	graph [size="120.44999999999999,120.44999999999999"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	138204069732864 [label="
 (1, 16)" fillcolor=darkolivegreen1]
	138204070048672 [label=SigmoidBackward0]
	138204070046368 -> 138204070048672
	138204070046368 [label=CatBackward0]
	138204070046608 -> 138204070046368
	138204070046608 [label=AddmmBackward0]
	138204070048144 -> 138204070046608
	138204343228256 [label="hidden_layer2.0.bias
 (1)" fillcolor=lightblue]
	138204343228256 -> 138204070048144
	138204070048144 [label=AccumulateGrad]
	138204070048096 -> 138204070046608
	138204070048096 [label=ReluBackward0]
	138204070047952 -> 138204070048096
	138204070047952 [label=AddmmBackward0]
	138204070047568 -> 138204070047952
	138204343233376 [label="hidden_layer1.0.bias
 (970)" fillcolor=lightblue]
	138204343233376 -> 138204070047568
	138204070047568 [label=AccumulateGrad]
	138204070047664 -> 138204070047952
	138204070047664 [label=ReluBackward0]
	138204070047328 -> 138204070047664
	138204070047328 [label=AddmmBackward0]
	138204070046032 -> 138204070047328
	138204343238496 [label="classifiers.0.bias
 (1018)" fillcolor=lightblue]
	138204343238496 -> 138204070046032
	138204070046032 [label=AccumulateGrad]
	138204070045984 -> 138204070047328
	138204070045984 [label=TanhBackward0]
	138204070045936 -> 138204070045984
	138204070045936 [label=AddmmBackward0]
	138204070045744 -> 138204070045936
	138204070045744 [label=SelectBackward0]
	138204070045648 -> 138204070045744
	138204070045648 [label=SliceBackward0]
	138204070045552 -> 138204070045648
	138204070045552 [label=NativeLayerNormBackward0]
	138204070045456 -> 138204070045552
	138204070045456 [label=AddBackward0]
	138204070045264 -> 138204070045456
	138204070045264 [label=ViewBackward0]
	138204070045024 -> 138204070045264
	138204070045024 [label=AddmmBackward0]
	138204070044928 -> 138204070045024
	138204343369008 [label="bert.encoder.layer.11.output.dense.bias
 (768)" fillcolor=lightblue]
	138204343369008 -> 138204070044928
	138204070044928 [label=AccumulateGrad]
	138204070045072 -> 138204070045024
	138204070045072 [label=ViewBackward0]
	138204070044832 -> 138204070045072
	138204070044832 [label=GeluBackward0]
	138204070044640 -> 138204070044832
	138204070044640 [label=ViewBackward0]
	138204070044544 -> 138204070044640
	138204070044544 [label=AddmmBackward0]
	138204070044448 -> 138204070044544
	138204069085568 [label="bert.encoder.layer.11.intermediate.dense.bias
 (3072)" fillcolor=lightblue]
	138204069085568 -> 138204070044448
	138204070044448 [label=AccumulateGrad]
	138204070044592 -> 138204070044544
	138204070044592 [label=ViewBackward0]
	138204070045216 -> 138204070044592
	138204070045216 [label=NativeLayerNormBackward0]
	138204070044304 -> 138204070045216
	138204070044304 [label=AddBackward0]
	138204070044112 -> 138204070044304
	138204070044112 [label=ViewBackward0]
	138204070044016 -> 138204070044112
	138204070044016 [label=AddmmBackward0]
	138204070043920 -> 138204070044016
	138204343369328 [label="bert.encoder.layer.11.attention.output.dense.bias
 (768)" fillcolor=lightblue]
	138204343369328 -> 138204070043920
	138204070043920 [label=AccumulateGrad]
	138204070043872 -> 138204070044016
	138204070043872 [label=ViewBackward0]
	138204070043824 -> 138204070043872
	138204070043824 [label=ViewBackward0]
	138204070043632 -> 138204070043824
	138204070043632 [label=TransposeBackward0]
	138204070043536 -> 138204070043632
	138204070043536 [label=ScaledDotProductFlashAttentionForCpuBackward0]
	138204070043440 -> 138204070043536
	138204070043440 [label=PermuteBackward0]
	138204070043248 -> 138204070043440
	138204070043248 [label=ViewBackward0]
	138204070043152 -> 138204070043248
	138204070043152 [label=ViewBackward0]
	138204070043056 -> 138204070043152
	138204070043056 [label=AddmmBackward0]
	138204070042960 -> 138204070043056
	138204343369248 [label="bert.encoder.layer.11.attention.self.query.bias
 (768)" fillcolor=lightblue]
	138204343369248 -> 138204070042960
	138204070042960 [label=AccumulateGrad]
	138204070042912 -> 138204070043056
	138204070042912 [label=TBackward0]
	138204070042816 -> 138204070042912
	138204343369168 [label="bert.encoder.layer.11.attention.self.query.weight
 (768, 768)" fillcolor=lightblue]
	138204343369168 -> 138204070042816
	138204070042816 [label=AccumulateGrad]
	138204070043392 -> 138204070043536
	138204070043392 [label=PermuteBackward0]
	138204070043008 -> 138204070043392
	138204070043008 [label=ViewBackward0]
	138204070042864 -> 138204070043008
	138204070042864 [label=ViewBackward0]
	138204070042768 -> 138204070042864
	138204070042768 [label=AddmmBackward0]
	138204070042672 -> 138204070042768
	138204343369408 [label="bert.encoder.layer.11.attention.self.key.bias
 (768)" fillcolor=lightblue]
	138204343369408 -> 138204070042672
	138204070042672 [label=AccumulateGrad]
	138204070042720 -> 138204070042768
	138204070042720 [label=TBackward0]
	138204070042528 -> 138204070042720
	138204343367728 [label="bert.encoder.layer.11.attention.self.key.weight
 (768, 768)" fillcolor=lightblue]
	138204343367728 -> 138204070042528
	138204070042528 [label=AccumulateGrad]
	138204070043728 -> 138204070043536
	138204070043728 [label=PermuteBackward0]
	138204070042624 -> 138204070043728
	138204070042624 [label=ViewBackward0]
	138204070042576 -> 138204070042624
	138204070042576 [label=ViewBackward0]
	138204070042480 -> 138204070042576
	138204070042480 [label=AddmmBackward0]
	138204070042384 -> 138204070042480
	138204343369568 [label="bert.encoder.layer.11.attention.self.value.bias
 (768)" fillcolor=lightblue]
	138204343369568 -> 138204070042384
	138204070042384 [label=AccumulateGrad]
	138204070042432 -> 138204070042480
	138204070042432 [label=TBackward0]
	138204070042240 -> 138204070042432
	138204343369488 [label="bert.encoder.layer.11.attention.self.value.weight
 (768, 768)" fillcolor=lightblue]
	138204343369488 -> 138204070042240
	138204070042240 [label=AccumulateGrad]
	138204070044208 -> 138204070044016
	138204070044208 [label=TBackward0]
	138204070043488 -> 138204070044208
	138204343369648 [label="bert.encoder.layer.11.attention.output.dense.weight
 (768, 768)" fillcolor=lightblue]
	138204343369648 -> 138204070043488
	138204070043488 [label=AccumulateGrad]
	138204070044256 -> 138204070045216
	138204069085408 [label="bert.encoder.layer.11.attention.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	138204069085408 -> 138204070044256
	138204070044256 [label=AccumulateGrad]
	138204070044400 -> 138204070045216
	138204069085248 [label="bert.encoder.layer.11.attention.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	138204069085248 -> 138204070044400
	138204070044400 [label=AccumulateGrad]
	138204070044736 -> 138204070044544
	138204070044736 [label=TBackward0]
	138204070044064 -> 138204070044736
	138204069085488 [label="bert.encoder.layer.11.intermediate.dense.weight
 (3072, 768)" fillcolor=lightblue]
	138204069085488 -> 138204070044064
	138204070044064 [label=AccumulateGrad]
	138204070045120 -> 138204070045024
	138204070045120 [label=TBackward0]
	138204070044688 -> 138204070045120
	138204069085648 [label="bert.encoder.layer.11.output.dense.weight
 (768, 3072)" fillcolor=lightblue]
	138204069085648 -> 138204070044688
	138204070044688 [label=AccumulateGrad]
	138204070045216 -> 138204070045456
	138204070045408 -> 138204070045552
	138204069085888 [label="bert.encoder.layer.11.output.LayerNorm.weight
 (768)" fillcolor=lightblue]
	138204069085888 -> 138204070045408
	138204070045408 [label=AccumulateGrad]
	138204070045840 -> 138204070045552
	138204069085728 [label="bert.encoder.layer.11.output.LayerNorm.bias
 (768)" fillcolor=lightblue]
	138204069085728 -> 138204070045840
	138204070045840 [label=AccumulateGrad]
	138204070046128 -> 138204070047328
	138204070046128 [label=TBackward0]
	138204070045600 -> 138204070046128
	138204389058064 [label="classifiers.0.weight
 (1018, 768)" fillcolor=lightblue]
	138204389058064 -> 138204070045600
	138204070045600 [label=AccumulateGrad]
	138204070047616 -> 138204070047952
	138204070047616 [label=TBackward0]
	138204070045696 -> 138204070047616
	138204343233536 [label="hidden_layer1.0.weight
 (970, 1018)" fillcolor=lightblue]
	138204343233536 -> 138204070045696
	138204070045696 [label=AccumulateGrad]
	138204070048240 -> 138204070046608
	138204070048240 [label=TBackward0]
	138204070045888 -> 138204070048240
	138204343228416 [label="hidden_layer2.0.weight
 (1, 970)" fillcolor=lightblue]
	138204343228416 -> 138204070045888
	138204070045888 [label=AccumulateGrad]
	138204070046272 -> 138204070046368
	138204070046272 [label=AddmmBackward0]
	138204070045312 -> 138204070046272
	138204343227936 [label="hidden_layer2.1.bias
 (1)" fillcolor=lightblue]
	138204343227936 -> 138204070045312
	138204070045312 [label=AccumulateGrad]
	138204070047424 -> 138204070046272
	138204070047424 [label=ReluBackward0]
	138204070047808 -> 138204070047424
	138204070047808 [label=AddmmBackward0]
	138204070045168 -> 138204070047808
	138204343233056 [label="hidden_layer1.1.bias
 (970)" fillcolor=lightblue]
	138204343233056 -> 138204070045168
	138204070045168 [label=AccumulateGrad]
	138204070045360 -> 138204070047808
	138204070045360 [label=ReluBackward0]
	138204070044784 -> 138204070045360
	138204070044784 [label=AddmmBackward0]
	138204070043776 -> 138204070044784
	138204343238176 [label="classifiers.1.bias
 (1018)" fillcolor=lightblue]
	138204343238176 -> 138204070043776
	138204070043776 [label=AccumulateGrad]
	138204070045984 -> 138204070044784
	138204070044880 -> 138204070044784
	138204070044880 [label=TBackward0]
	138204070043968 -> 138204070044880
	138204343238336 [label="classifiers.1.weight
 (1018, 768)" fillcolor=lightblue]
	138204343238336 -> 138204070043968
	138204070043968 [label=AccumulateGrad]
	138204070045792 -> 138204070047808
	138204070045792 [label=TBackward0]
	138204070044352 -> 138204070045792
	138204343233216 [label="hidden_layer1.1.weight
 (970, 1018)" fillcolor=lightblue]
	138204343233216 -> 138204070044352
	138204070044352 [label=AccumulateGrad]
	138204070048000 -> 138204070046272
	138204070048000 [label=TBackward0]
	138204070044496 -> 138204070048000
	138204343228096 [label="hidden_layer2.1.weight
 (1, 970)" fillcolor=lightblue]
	138204343228096 -> 138204070044496
	138204070044496 [label=AccumulateGrad]
	138204070046512 -> 138204070046368
	138204070046512 [label=AddmmBackward0]
	138204070043296 -> 138204070046512
	138204343227616 [label="hidden_layer2.2.bias
 (1)" fillcolor=lightblue]
	138204343227616 -> 138204070043296
	138204070043296 [label=AccumulateGrad]
	138204070044976 -> 138204070046512
	138204070044976 [label=ReluBackward0]
	138204070047232 -> 138204070044976
	138204070047232 [label=AddmmBackward0]
	138204070043200 -> 138204070047232
	138204343232736 [label="hidden_layer1.2.bias
 (970)" fillcolor=lightblue]
	138204343232736 -> 138204070043200
	138204070043200 [label=AccumulateGrad]
	138204070043680 -> 138204070047232
	138204070043680 [label=ReluBackward0]
	138204070043104 -> 138204070043680
	138204070043104 [label=AddmmBackward0]
	138204070042144 -> 138204070043104
	138204343237856 [label="classifiers.2.bias
 (1018)" fillcolor=lightblue]
	138204343237856 -> 138204070042144
	138204070042144 [label=AccumulateGrad]
	138204070045984 -> 138204070043104
	138204070042192 -> 138204070043104
	138204070042192 [label=TBackward0]
	138204070042096 -> 138204070042192
	138204343238016 [label="classifiers.2.weight
 (1018, 768)" fillcolor=lightblue]
	138204343238016 -> 138204070042096
	138204070042096 [label=AccumulateGrad]
	138204070043584 -> 138204070047232
	138204070043584 [label=TBackward0]
	138204070041952 -> 138204070043584
	138204343232896 [label="hidden_layer1.2.weight
 (970, 1018)" fillcolor=lightblue]
	138204343232896 -> 138204070041952
	138204070041952 [label=AccumulateGrad]
	138204070045504 -> 138204070046512
	138204070045504 [label=TBackward0]
	138204070042048 -> 138204070045504
	138204343227776 [label="hidden_layer2.2.weight
 (1, 970)" fillcolor=lightblue]
	138204343227776 -> 138204070042048
	138204070042048 [label=AccumulateGrad]
	138204070046224 -> 138204070046368
	138204070046224 [label=AddmmBackward0]
	138204070041904 -> 138204070046224
	138204343227296 [label="hidden_layer2.3.bias
 (1)" fillcolor=lightblue]
	138204343227296 -> 138204070041904
	138204070041904 [label=AccumulateGrad]
	138204070042336 -> 138204070046224
	138204070042336 [label=ReluBackward0]
	138204070044160 -> 138204070042336
	138204070044160 [label=AddmmBackward0]
	138204070041808 -> 138204070044160
	138204343232416 [label="hidden_layer1.3.bias
 (970)" fillcolor=lightblue]
	138204343232416 -> 138204070041808
	138204070041808 [label=AccumulateGrad]
	138204070041760 -> 138204070044160
	138204070041760 [label=ReluBackward0]
	138204070041712 -> 138204070041760
	138204070041712 [label=AddmmBackward0]
	138204070041520 -> 138204070041712
	138204343237536 [label="classifiers.3.bias
 (1018)" fillcolor=lightblue]
	138204343237536 -> 138204070041520
	138204070041520 [label=AccumulateGrad]
	138204070045984 -> 138204070041712
	138204070041472 -> 138204070041712
	138204070041472 [label=TBackward0]
	138204070041376 -> 138204070041472
	138204343237696 [label="classifiers.3.weight
 (1018, 768)" fillcolor=lightblue]
	138204343237696 -> 138204070041376
	138204070041376 [label=AccumulateGrad]
	138204070042000 -> 138204070044160
	138204070042000 [label=TBackward0]
	138204070041424 -> 138204070042000
	138204343232576 [label="hidden_layer1.3.weight
 (970, 1018)" fillcolor=lightblue]
	138204343232576 -> 138204070041424
	138204070041424 [label=AccumulateGrad]
	138204070043344 -> 138204070046224
	138204070043344 [label=TBackward0]
	138204070041616 -> 138204070043344
	138204343227456 [label="hidden_layer2.3.weight
 (1, 970)" fillcolor=lightblue]
	138204343227456 -> 138204070041616
	138204070041616 [label=AccumulateGrad]
	138204070046416 -> 138204070046368
	138204070046416 [label=AddmmBackward0]
	138204070041184 -> 138204070046416
	138204389058624 [label="hidden_layer2.4.bias
 (1)" fillcolor=lightblue]
	138204389058624 -> 138204070041184
	138204070041184 [label=AccumulateGrad]
	138204070041664 -> 138204070046416
	138204070041664 [label=ReluBackward0]
	138204070042288 -> 138204070041664
	138204070042288 [label=AddmmBackward0]
	138204070041088 -> 138204070042288
	138204343232096 [label="hidden_layer1.4.bias
 (970)" fillcolor=lightblue]
	138204343232096 -> 138204070041088
	138204070041088 [label=AccumulateGrad]
	138204070041232 -> 138204070042288
	138204070041232 [label=ReluBackward0]
	138204070040992 -> 138204070041232
	138204070040992 [label=AddmmBackward0]
	138204070040800 -> 138204070040992
	138204343237216 [label="classifiers.4.bias
 (1018)" fillcolor=lightblue]
	138204343237216 -> 138204070040800
	138204070040800 [label=AccumulateGrad]
	138204070045984 -> 138204070040992
	138204070040944 -> 138204070040992
	138204070040944 [label=TBackward0]
	138204070040848 -> 138204070040944
	138204343237376 [label="classifiers.4.weight
 (1018, 768)" fillcolor=lightblue]
	138204343237376 -> 138204070040848
	138204070040848 [label=AccumulateGrad]
	138204070041280 -> 138204070042288
	138204070041280 [label=TBackward0]
	138204070040704 -> 138204070041280
	138204343232256 [label="hidden_layer1.4.weight
 (970, 1018)" fillcolor=lightblue]
	138204343232256 -> 138204070040704
	138204070040704 [label=AccumulateGrad]
	138204070041856 -> 138204070046416
	138204070041856 [label=TBackward0]
	138204070040896 -> 138204070041856
	138204389060704 [label="hidden_layer2.4.weight
 (1, 970)" fillcolor=lightblue]
	138204389060704 -> 138204070040896
	138204070040896 [label=AccumulateGrad]
	138204070046656 -> 138204070046368
	138204070046656 [label=AddmmBackward0]
	138204070040656 -> 138204070046656
	138204389059184 [label="hidden_layer2.5.bias
 (1)" fillcolor=lightblue]
	138204389059184 -> 138204070040656
	138204070040656 [label=AccumulateGrad]
	138204070041136 -> 138204070046656
	138204070041136 [label=ReluBackward0]
	138204070041568 -> 138204070041136
	138204070041568 [label=AddmmBackward0]
	138204070040560 -> 138204070041568
	138204343231776 [label="hidden_layer1.5.bias
 (970)" fillcolor=lightblue]
	138204343231776 -> 138204070040560
	138204070040560 [label=AccumulateGrad]
	138204070040512 -> 138204070041568
	138204070040512 [label=ReluBackward0]
	138204070040464 -> 138204070040512
	138204070040464 [label=AddmmBackward0]
	138204070040272 -> 138204070040464
	138204343236896 [label="classifiers.5.bias
 (1018)" fillcolor=lightblue]
	138204343236896 -> 138204070040272
	138204070040272 [label=AccumulateGrad]
	138204070045984 -> 138204070040464
	138204070040224 -> 138204070040464
	138204070040224 [label=TBackward0]
	138204070040128 -> 138204070040224
	138204343237056 [label="classifiers.5.weight
 (1018, 768)" fillcolor=lightblue]
	138204343237056 -> 138204070040128
	138204070040128 [label=AccumulateGrad]
	138204070040752 -> 138204070041568
	138204070040752 [label=TBackward0]
	138204070040176 -> 138204070040752
	138204343231936 [label="hidden_layer1.5.weight
 (970, 1018)" fillcolor=lightblue]
	138204343231936 -> 138204070040176
	138204070040176 [label=AccumulateGrad]
	138204070041328 -> 138204070046656
	138204070041328 [label=TBackward0]
	138204070040368 -> 138204070041328
	138204389058784 [label="hidden_layer2.5.weight
 (1, 970)" fillcolor=lightblue]
	138204389058784 -> 138204070040368
	138204070040368 [label=AccumulateGrad]
	138204070046704 -> 138204070046368
	138204070046704 [label=AddmmBackward0]
	138204070039936 -> 138204070046704
	138204389059904 [label="hidden_layer2.6.bias
 (1)" fillcolor=lightblue]
	138204389059904 -> 138204070039936
	138204070039936 [label=AccumulateGrad]
	138204070040416 -> 138204070046704
	138204070040416 [label=ReluBackward0]
	138204070041040 -> 138204070040416
	138204070041040 [label=AddmmBackward0]
	138204070039840 -> 138204070041040
	138204343231456 [label="hidden_layer1.6.bias
 (970)" fillcolor=lightblue]
	138204343231456 -> 138204070039840
	138204070039840 [label=AccumulateGrad]
	138204070039984 -> 138204070041040
	138204070039984 [label=ReluBackward0]
	138204070039744 -> 138204070039984
	138204070039744 [label=AddmmBackward0]
	138204070039552 -> 138204070039744
	138204343236576 [label="classifiers.6.bias
 (1018)" fillcolor=lightblue]
	138204343236576 -> 138204070039552
	138204070039552 [label=AccumulateGrad]
	138204070045984 -> 138204070039744
	138204070039696 -> 138204070039744
	138204070039696 [label=TBackward0]
	138204070039600 -> 138204070039696
	138204343236736 [label="classifiers.6.weight
 (1018, 768)" fillcolor=lightblue]
	138204343236736 -> 138204070039600
	138204070039600 [label=AccumulateGrad]
	138204070040032 -> 138204070041040
	138204070040032 [label=TBackward0]
	138204070039456 -> 138204070040032
	138204343231616 [label="hidden_layer1.6.weight
 (970, 1018)" fillcolor=lightblue]
	138204343231616 -> 138204070039456
	138204070039456 [label=AccumulateGrad]
	138204070040608 -> 138204070046704
	138204070040608 [label=TBackward0]
	138204070039648 -> 138204070040608
	138204389058704 [label="hidden_layer2.6.weight
 (1, 970)" fillcolor=lightblue]
	138204389058704 -> 138204070039648
	138204070039648 [label=AccumulateGrad]
	138204070046560 -> 138204070046368
	138204070046560 [label=AddmmBackward0]
	138204070039408 -> 138204070046560
	138204389060064 [label="hidden_layer2.7.bias
 (1)" fillcolor=lightblue]
	138204389060064 -> 138204070039408
	138204070039408 [label=AccumulateGrad]
	138204070039888 -> 138204070046560
	138204070039888 [label=ReluBackward0]
	138204070040320 -> 138204070039888
	138204070040320 [label=AddmmBackward0]
	138204070039312 -> 138204070040320
	138204343231136 [label="hidden_layer1.7.bias
 (970)" fillcolor=lightblue]
	138204343231136 -> 138204070039312
	138204070039312 [label=AccumulateGrad]
	138204070039264 -> 138204070040320
	138204070039264 [label=ReluBackward0]
	138204070039216 -> 138204070039264
	138204070039216 [label=AddmmBackward0]
	138204070038976 -> 138204070039216
	138204343236256 [label="classifiers.7.bias
 (1018)" fillcolor=lightblue]
	138204343236256 -> 138204070038976
	138204070038976 [label=AccumulateGrad]
	138204070045984 -> 138204070039216
	138204070039120 -> 138204070039216
	138204070039120 [label=TBackward0]
	138204070038928 -> 138204070039120
	138204343236416 [label="classifiers.7.weight
 (1018, 768)" fillcolor=lightblue]
	138204343236416 -> 138204070038928
	138204070038928 [label=AccumulateGrad]
	138204070039504 -> 138204070040320
	138204070039504 [label=TBackward0]
	138204070038784 -> 138204070039504
	138204343231296 [label="hidden_layer1.7.weight
 (970, 1018)" fillcolor=lightblue]
	138204343231296 -> 138204070038784
	138204070038784 [label=AccumulateGrad]
	138204070040080 -> 138204070046560
	138204070040080 [label=TBackward0]
	138204070038880 -> 138204070040080
	138204389060144 [label="hidden_layer2.7.weight
 (1, 970)" fillcolor=lightblue]
	138204389060144 -> 138204070038880
	138204070038880 [label=AccumulateGrad]
	138204070046800 -> 138204070046368
	138204070046800 [label=AddmmBackward0]
	138204070038736 -> 138204070046800
	138204389060384 [label="hidden_layer2.8.bias
 (1)" fillcolor=lightblue]
	138204389060384 -> 138204070038736
	138204070038736 [label=AccumulateGrad]
	138204070039168 -> 138204070046800
	138204070039168 [label=ReluBackward0]
	138204070039792 -> 138204070039168
	138204070039792 [label=AddmmBackward0]
	138204070038640 -> 138204070039792
	138204343230816 [label="hidden_layer1.8.bias
 (970)" fillcolor=lightblue]
	138204343230816 -> 138204070038640
	138204070038640 [label=AccumulateGrad]
	138204070038592 -> 138204070039792
	138204070038592 [label=ReluBackward0]
	138204070038544 -> 138204070038592
	138204070038544 [label=AddmmBackward0]
	138204070038352 -> 138204070038544
	138204343235936 [label="classifiers.8.bias
 (1018)" fillcolor=lightblue]
	138204343235936 -> 138204070038352
	138204070038352 [label=AccumulateGrad]
	138204070045984 -> 138204070038544
	138204070038304 -> 138204070038544
	138204070038304 [label=TBackward0]
	138204070038208 -> 138204070038304
	138204343236096 [label="classifiers.8.weight
 (1018, 768)" fillcolor=lightblue]
	138204343236096 -> 138204070038208
	138204070038208 [label=AccumulateGrad]
	138204070038832 -> 138204070039792
	138204070038832 [label=TBackward0]
	138204070038256 -> 138204070038832
	138204343230976 [label="hidden_layer1.8.weight
 (970, 1018)" fillcolor=lightblue]
	138204343230976 -> 138204070038256
	138204070038256 [label=AccumulateGrad]
	138204070039360 -> 138204070046800
	138204070039360 [label=TBackward0]
	138204070038448 -> 138204070039360
	138204389060304 [label="hidden_layer2.8.weight
 (1, 970)" fillcolor=lightblue]
	138204389060304 -> 138204070038448
	138204070038448 [label=AccumulateGrad]
	138204070046896 -> 138204070046368
	138204070046896 [label=AddmmBackward0]
	138204070038016 -> 138204070046896
	138204389060224 [label="hidden_layer2.9.bias
 (1)" fillcolor=lightblue]
	138204389060224 -> 138204070038016
	138204070038016 [label=AccumulateGrad]
	138204070038496 -> 138204070046896
	138204070038496 [label=ReluBackward0]
	138204070039072 -> 138204070038496
	138204070039072 [label=AddmmBackward0]
	138204070037920 -> 138204070039072
	138204343230496 [label="hidden_layer1.9.bias
 (970)" fillcolor=lightblue]
	138204343230496 -> 138204070037920
	138204070037920 [label=AccumulateGrad]
	138204070038064 -> 138204070039072
	138204070038064 [label=ReluBackward0]
	138204070037824 -> 138204070038064
	138204070037824 [label=AddmmBackward0]
	138204070037632 -> 138204070037824
	138204343235616 [label="classifiers.9.bias
 (1018)" fillcolor=lightblue]
	138204343235616 -> 138204070037632
	138204070037632 [label=AccumulateGrad]
	138204070045984 -> 138204070037824
	138204070037776 -> 138204070037824
	138204070037776 [label=TBackward0]
	138204070037680 -> 138204070037776
	138204343235776 [label="classifiers.9.weight
 (1018, 768)" fillcolor=lightblue]
	138204343235776 -> 138204070037680
	138204070037680 [label=AccumulateGrad]
	138204070038112 -> 138204070039072
	138204070038112 [label=TBackward0]
	138204070037536 -> 138204070038112
	138204343230656 [label="hidden_layer1.9.weight
 (970, 1018)" fillcolor=lightblue]
	138204343230656 -> 138204070037536
	138204070037536 [label=AccumulateGrad]
	138204070038688 -> 138204070046896
	138204070038688 [label=TBackward0]
	138204070037728 -> 138204070038688
	138204389060464 [label="hidden_layer2.9.weight
 (1, 970)" fillcolor=lightblue]
	138204389060464 -> 138204070037728
	138204070037728 [label=AccumulateGrad]
	138204070046752 -> 138204070046368
	138204070046752 [label=AddmmBackward0]
	138204070037488 -> 138204070046752
	138204389060544 [label="hidden_layer2.10.bias
 (1)" fillcolor=lightblue]
	138204389060544 -> 138204070037488
	138204070037488 [label=AccumulateGrad]
	138204070037968 -> 138204070046752
	138204070037968 [label=ReluBackward0]
	138204070038400 -> 138204070037968
	138204070038400 [label=AddmmBackward0]
	138204070037392 -> 138204070038400
	138204343230176 [label="hidden_layer1.10.bias
 (970)" fillcolor=lightblue]
	138204343230176 -> 138204070037392
	138204070037392 [label=AccumulateGrad]
	138204070037344 -> 138204070038400
	138204070037344 [label=ReluBackward0]
	138204070037296 -> 138204070037344
	138204070037296 [label=AddmmBackward0]
	138204070037104 -> 138204070037296
	138204343235296 [label="classifiers.10.bias
 (1018)" fillcolor=lightblue]
	138204343235296 -> 138204070037104
	138204070037104 [label=AccumulateGrad]
	138204070045984 -> 138204070037296
	138204070037056 -> 138204070037296
	138204070037056 [label=TBackward0]
	138204070036960 -> 138204070037056
	138204343235456 [label="classifiers.10.weight
 (1018, 768)" fillcolor=lightblue]
	138204343235456 -> 138204070036960
	138204070036960 [label=AccumulateGrad]
	138204070037584 -> 138204070038400
	138204070037584 [label=TBackward0]
	138204070037008 -> 138204070037584
	138204343230336 [label="hidden_layer1.10.weight
 (970, 1018)" fillcolor=lightblue]
	138204343230336 -> 138204070037008
	138204070037008 [label=AccumulateGrad]
	138204070038160 -> 138204070046752
	138204070038160 [label=TBackward0]
	138204070037200 -> 138204070038160
	138204389059504 [label="hidden_layer2.10.weight
 (1, 970)" fillcolor=lightblue]
	138204389059504 -> 138204070037200
	138204070037200 [label=AccumulateGrad]
	138204070046848 -> 138204070046368
	138204070046848 [label=AddmmBackward0]
	138204070036768 -> 138204070046848
	138204389057584 [label="hidden_layer2.11.bias
 (1)" fillcolor=lightblue]
	138204389057584 -> 138204070036768
	138204070036768 [label=AccumulateGrad]
	138204070037248 -> 138204070046848
	138204070037248 [label=ReluBackward0]
	138204070037872 -> 138204070037248
	138204070037872 [label=AddmmBackward0]
	138204070036672 -> 138204070037872
	138204343229856 [label="hidden_layer1.11.bias
 (970)" fillcolor=lightblue]
	138204343229856 -> 138204070036672
	138204070036672 [label=AccumulateGrad]
	138204070036816 -> 138204070037872
	138204070036816 [label=ReluBackward0]
	138204070036576 -> 138204070036816
	138204070036576 [label=AddmmBackward0]
	138204070036384 -> 138204070036576
	138204343234976 [label="classifiers.11.bias
 (1018)" fillcolor=lightblue]
	138204343234976 -> 138204070036384
	138204070036384 [label=AccumulateGrad]
	138204070045984 -> 138204070036576
	138204070036528 -> 138204070036576
	138204070036528 [label=TBackward0]
	138204070036432 -> 138204070036528
	138204343235136 [label="classifiers.11.weight
 (1018, 768)" fillcolor=lightblue]
	138204343235136 -> 138204070036432
	138204070036432 [label=AccumulateGrad]
	138204070036864 -> 138204070037872
	138204070036864 [label=TBackward0]
	138204070036288 -> 138204070036864
	138204343230016 [label="hidden_layer1.11.weight
 (970, 1018)" fillcolor=lightblue]
	138204343230016 -> 138204070036288
	138204070036288 [label=AccumulateGrad]
	138204070037440 -> 138204070046848
	138204070037440 [label=TBackward0]
	138204070036480 -> 138204070037440
	138204389060624 [label="hidden_layer2.11.weight
 (1, 970)" fillcolor=lightblue]
	138204389060624 -> 138204070036480
	138204070036480 [label=AccumulateGrad]
	138204070049488 -> 138204070046368
	138204070049488 [label=AddmmBackward0]
	138204070036240 -> 138204070049488
	138204389059424 [label="hidden_layer2.12.bias
 (1)" fillcolor=lightblue]
	138204389059424 -> 138204070036240
	138204070036240 [label=AccumulateGrad]
	138204070036720 -> 138204070049488
	138204070036720 [label=ReluBackward0]
	138204070037152 -> 138204070036720
	138204070037152 [label=AddmmBackward0]
	138204070036144 -> 138204070037152
	138204343229536 [label="hidden_layer1.12.bias
 (970)" fillcolor=lightblue]
	138204343229536 -> 138204070036144
	138204070036144 [label=AccumulateGrad]
	138204070036096 -> 138204070037152
	138204070036096 [label=ReluBackward0]
	138204070036048 -> 138204070036096
	138204070036048 [label=AddmmBackward0]
	138204070035856 -> 138204070036048
	138204343234656 [label="classifiers.12.bias
 (1018)" fillcolor=lightblue]
	138204343234656 -> 138204070035856
	138204070035856 [label=AccumulateGrad]
	138204070045984 -> 138204070036048
	138204070035808 -> 138204070036048
	138204070035808 [label=TBackward0]
	138204070035712 -> 138204070035808
	138204343234816 [label="classifiers.12.weight
 (1018, 768)" fillcolor=lightblue]
	138204343234816 -> 138204070035712
	138204070035712 [label=AccumulateGrad]
	138204070036336 -> 138204070037152
	138204070036336 [label=TBackward0]
	138204070035760 -> 138204070036336
	138204343229696 [label="hidden_layer1.12.weight
 (970, 1018)" fillcolor=lightblue]
	138204343229696 -> 138204070035760
	138204070035760 [label=AccumulateGrad]
	138204070036912 -> 138204070049488
	138204070036912 [label=TBackward0]
	138204070035952 -> 138204070036912
	138204389057504 [label="hidden_layer2.12.weight
 (1, 970)" fillcolor=lightblue]
	138204389057504 -> 138204070035952
	138204070035952 [label=AccumulateGrad]
	138204070048528 -> 138204070046368
	138204070048528 [label=AddmmBackward0]
	138204070035520 -> 138204070048528
	138204389057664 [label="hidden_layer2.13.bias
 (1)" fillcolor=lightblue]
	138204389057664 -> 138204070035520
	138204070035520 [label=AccumulateGrad]
	138204070036000 -> 138204070048528
	138204070036000 [label=ReluBackward0]
	138204070036624 -> 138204070036000
	138204070036624 [label=AddmmBackward0]
	138204070035568 -> 138204070036624
	138204343229216 [label="hidden_layer1.13.bias
 (970)" fillcolor=lightblue]
	138204343229216 -> 138204070035568
	138204070035568 [label=AccumulateGrad]
	138204070035616 -> 138204070036624
	138204070035616 [label=ReluBackward0]
	138204069688080 -> 138204070035616
	138204069688080 [label=AddmmBackward0]
	138204069688512 -> 138204069688080
	138204343234336 [label="classifiers.13.bias
 (1018)" fillcolor=lightblue]
	138204343234336 -> 138204069688512
	138204069688512 [label=AccumulateGrad]
	138204070045984 -> 138204069688080
	138204069688320 -> 138204069688080
	138204069688320 [label=TBackward0]
	138204069691344 -> 138204069688320
	138204343234496 [label="classifiers.13.weight
 (1018, 768)" fillcolor=lightblue]
	138204343234496 -> 138204069691344
	138204069691344 [label=AccumulateGrad]
	138204069679584 -> 138204070036624
	138204069679584 [label=TBackward0]
	138204069688992 -> 138204069679584
	138204343229376 [label="hidden_layer1.13.weight
 (970, 1018)" fillcolor=lightblue]
	138204343229376 -> 138204069688992
	138204069688992 [label=AccumulateGrad]
	138204070036192 -> 138204070048528
	138204070036192 [label=TBackward0]
	138204070035904 -> 138204070036192
	138204389057984 [label="hidden_layer2.13.weight
 (1, 970)" fillcolor=lightblue]
	138204389057984 -> 138204070035904
	138204070035904 [label=AccumulateGrad]
	138204070048384 -> 138204070046368
	138204070048384 [label=AddmmBackward0]
	138204070035664 -> 138204070048384
	138204389058464 [label="hidden_layer2.14.bias
 (1)" fillcolor=lightblue]
	138204389058464 -> 138204070035664
	138204070035664 [label=AccumulateGrad]
	138204069689136 -> 138204070048384
	138204069689136 [label=ReluBackward0]
	138204069675360 -> 138204069689136
	138204069675360 [label=AddmmBackward0]
	138204069689040 -> 138204069675360
	138204343228896 [label="hidden_layer1.14.bias
 (970)" fillcolor=lightblue]
	138204343228896 -> 138204069689040
	138204069689040 [label=AccumulateGrad]
	138204069689088 -> 138204069675360
	138204069689088 [label=ReluBackward0]
	138204069689472 -> 138204069689088
	138204069689472 [label=AddmmBackward0]
	138204069689568 -> 138204069689472
	138204343234016 [label="classifiers.14.bias
 (1018)" fillcolor=lightblue]
	138204343234016 -> 138204069689568
	138204069689568 [label=AccumulateGrad]
	138204070045984 -> 138204069689472
	138204069689664 -> 138204069689472
	138204069689664 [label=TBackward0]
	138204069689856 -> 138204069689664
	138204343234176 [label="classifiers.14.weight
 (1018, 768)" fillcolor=lightblue]
	138204343234176 -> 138204069689856
	138204069689856 [label=AccumulateGrad]
	138204069688800 -> 138204069675360
	138204069688800 [label=TBackward0]
	138204069689808 -> 138204069688800
	138204343229056 [label="hidden_layer1.14.weight
 (970, 1018)" fillcolor=lightblue]
	138204343229056 -> 138204069689808
	138204069689808 [label=AccumulateGrad]
	138204069688224 -> 138204070048384
	138204069688224 [label=TBackward0]
	138204069689712 -> 138204069688224
	138204389057824 [label="hidden_layer2.14.weight
 (1, 970)" fillcolor=lightblue]
	138204389057824 -> 138204069689712
	138204069689712 [label=AccumulateGrad]
	138204070048432 -> 138204070046368
	138204070048432 [label=AddmmBackward0]
	138204069689952 -> 138204070048432
	138204389058304 [label="hidden_layer2.15.bias
 (1)" fillcolor=lightblue]
	138204389058304 -> 138204069689952
	138204069689952 [label=AccumulateGrad]
	138204069689520 -> 138204070048432
	138204069689520 [label=ReluBackward0]
	138204069688608 -> 138204069689520
	138204069688608 [label=AddmmBackward0]
	138204069690144 -> 138204069688608
	138204343228576 [label="hidden_layer1.15.bias
 (970)" fillcolor=lightblue]
	138204343228576 -> 138204069690144
	138204069690144 [label=AccumulateGrad]
	138204069689904 -> 138204069688608
	138204069689904 [label=ReluBackward0]
	138204069690048 -> 138204069689904
	138204069690048 [label=AddmmBackward0]
	138204069690480 -> 138204069690048
	138204343233696 [label="classifiers.15.bias
 (1018)" fillcolor=lightblue]
	138204343233696 -> 138204069690480
	138204069690480 [label=AccumulateGrad]
	138204070045984 -> 138204069690048
	138204069690192 -> 138204069690048
	138204069690192 [label=TBackward0]
	138204069690432 -> 138204069690192
	138204343233856 [label="classifiers.15.weight
 (1018, 768)" fillcolor=lightblue]
	138204343233856 -> 138204069690432
	138204069690432 [label=AccumulateGrad]
	138204069689760 -> 138204069688608
	138204069689760 [label=TBackward0]
	138204069690336 -> 138204069689760
	138204343228736 [label="hidden_layer1.15.weight
 (970, 1018)" fillcolor=lightblue]
	138204343228736 -> 138204069690336
	138204069690336 [label=AccumulateGrad]
	138204069688944 -> 138204070048432
	138204069688944 [label=TBackward0]
	138204069690240 -> 138204069688944
	138204389058384 [label="hidden_layer2.15.weight
 (1, 970)" fillcolor=lightblue]
	138204389058384 -> 138204069690240
	138204069690240 [label=AccumulateGrad]
	138204070048672 -> 138204069732864
}
