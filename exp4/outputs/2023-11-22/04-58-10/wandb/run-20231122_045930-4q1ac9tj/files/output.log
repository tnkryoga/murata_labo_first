/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
tokenizer_config.json: 100% 110/110 [00:00<00:00, 166kB/s]
vocab.txt: 100% 15.7k/15.7k [00:00<00:00, 18.5MB/s]
config.json: 100% 478/478 [00:00<00:00, 1.33MB/s]

pytorch_model.bin: 100% 359M/359M [00:02<00:00, 178MB/s]
Error executing job with overrides: []
Traceback (most recent call last):
  File "/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp4/main.py", line 486, in main
    model = MaltiLabelClassifierModel(
  File "/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp4/main.py", line 181, in __init__
    self.metrics_per_label = torchmetrics.MetricCollection(
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/collections.py", line 188, in __init__
    self.add_metrics(metrics, *additional_metrics)
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/collections.py", line 408, in add_metrics
    raise ValueError(
ValueError: You have passes extra arguments ({'recall_label_0': BinaryRecall(), 'recall_label_1': BinaryRecall(), 'recall_label_2': BinaryRecall(), 'recall_label_3': BinaryRecall(), 'recall_label_4': BinaryRecall(), 'recall_label_5': BinaryRecall(), 'recall_label_6': BinaryRecall(), 'recall_label_7': BinaryRecall(), 'recall_label_8': BinaryRecall(), 'recall_label_9': BinaryRecall(), 'recall_label_10': BinaryRecall(), 'recall_label_11': BinaryRecall(), 'recall_label_12': BinaryRecall(), 'recall_label_13': BinaryRecall(), 'recall_label_14': BinaryRecall(), 'recall_label_15': BinaryRecall()}, {'f1score_label_0': BinaryF1Score(), 'f1score_label_1': BinaryF1Score(), 'f1score_label_2': BinaryF1Score(), 'f1score_label_3': BinaryF1Score(), 'f1score_label_4': BinaryF1Score(), 'f1score_label_5': BinaryF1Score(), 'f1score_label_6': BinaryF1Score(), 'f1score_label_7': BinaryF1Score(), 'f1score_label_8': BinaryF1Score(), 'f1score_label_9': BinaryF1Score(), 'f1score_label_10': BinaryF1Score(), 'f1score_label_11': BinaryF1Score(), 'f1score_label_12': BinaryF1Score(), 'f1score_label_13': BinaryF1Score(), 'f1score_label_14': BinaryF1Score(), 'f1score_label_15': BinaryF1Score()}) which are not compatible with first passed dictionary {'accuracy_label_0': BinaryAccuracy(), 'accuracy_label_1': BinaryAccuracy(), 'accuracy_label_2': BinaryAccuracy(), 'accuracy_label_3': BinaryAccuracy(), 'accuracy_label_4': BinaryAccuracy(), 'accuracy_label_5': BinaryAccuracy(), 'accuracy_label_6': BinaryAccuracy(), 'accuracy_label_7': BinaryAccuracy(), 'accuracy_label_8': BinaryAccuracy(), 'accuracy_label_9': BinaryAccuracy(), 'accuracy_label_10': BinaryAccuracy(), 'accuracy_label_11': BinaryAccuracy(), 'accuracy_label_12': BinaryAccuracy(), 'accuracy_label_13': BinaryAccuracy(), 'accuracy_label_14': BinaryAccuracy(), 'accuracy_label_15': BinaryAccuracy()} so they will be ignored.
Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.