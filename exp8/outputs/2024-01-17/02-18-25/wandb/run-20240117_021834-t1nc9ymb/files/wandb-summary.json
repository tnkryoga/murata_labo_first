{"train/loss": 0.6929423213005066, "epoch": 1, "trainer/global_step": 617, "_timestamp": 1705458254.6698291, "_runtime": 340.0167942047119, "_step": 14, "val_loss": 0.6850304007530212, "val/multilabelaccuracy": 0.8834837079048157, "val/multilabelprecision": 0.12555506825447083, "val/multilabelrecall": 0.11761317402124405, "val/multilabelf1score": 0.09829811751842499, "val/multilabelmatthewscorrcoef": 0.509869396686554, "val/accuracy_label_\u3042\u3044\u3065\u3061": 0.661190390586853, "val/presicion_label_\u3042\u3044\u3065\u3061": 0.6711071729660034, "val/recall_label_\u3042\u3044\u3065\u3061": 0.939105212688446, "val/f1score_label_\u3042\u3044\u3065\u3061": 0.7828038930892944, "val/accuracy_label_\u611f\u5fc3": 0.7002424001693726, "val/presicion_label_\u611f\u5fc3": 0.3333333432674408, "val/recall_label_\u611f\u5fc3": 0.0018001800635829568, "val/f1score_label_\u611f\u5fc3": 0.003581020515412092, "val/accuracy_label_\u8a55\u4fa1": 0.957177460193634, "val/presicion_label_\u8a55\u4fa1": 0.0, "val/recall_label_\u8a55\u4fa1": 0.0, "val/f1score_label_\u8a55\u4fa1": 0.0, "val/accuracy_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.9240506291389465, "val/presicion_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "val/recall_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "val/f1score_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "val/accuracy_label_\u540c\u610f": 0.9539455771446228, "val/presicion_label_\u540c\u610f": 0.0, "val/recall_label_\u540c\u610f": 0.0, "val/f1score_label_\u540c\u610f": 0.0, "val/accuracy_label_\u7d0d\u5f97": 0.9711823463439941, "val/presicion_label_\u7d0d\u5f97": 0.0, "val/recall_label_\u7d0d\u5f97": 0.0, "val/f1score_label_\u7d0d\u5f97": 0.0, "val/accuracy_label_\u9a5a\u304d": 0.9706436991691589, "val/presicion_label_\u9a5a\u304d": 0.0, "val/recall_label_\u9a5a\u304d": 0.0, "val/f1score_label_\u9a5a\u304d": 0.0, "val/accuracy_label_\u305d\u306e\u4ed6": 0.9294371008872986, "val/presicion_label_\u305d\u306e\u4ed6": 0.0, "val/recall_label_\u305d\u306e\u4ed6": 0.0, "val/f1score_label_\u305d\u306e\u4ed6": 0.0, "train_loss": 0.6874833703041077, "train/multilabelaccuracy": 0.8702441453933716, "train/multilabelprecision": 0.1379166841506958, "train/multilabelrecall": 0.13535232841968536, "train/multilabelf1score": 0.11608660221099854, "train/multilabelmatthewscorrcoef": 0.48042580485343933, "train/accuracy_label_\u3042\u3044\u3065\u3061": 0.6469359993934631, "train/presicion_label_\u3042\u3044\u3065\u3061": 0.6517629027366638, "train/recall_label_\u3042\u3044\u3065\u3061": 0.9796722531318665, "train/f1score_label_\u3042\u3044\u3065\u3061": 0.7827636003494263, "train/accuracy_label_\u611f\u5fc3": 0.692727267742157, "train/presicion_label_\u611f\u5fc3": 0.25357142090797424, "train/recall_label_\u611f\u5fc3": 0.01604519784450531, "train/f1score_label_\u611f\u5fc3": 0.030180659145116806, "train/accuracy_label_\u8a55\u4fa1": 0.9567676782608032, "train/presicion_label_\u8a55\u4fa1": 0.0, "train/recall_label_\u8a55\u4fa1": 0.0, "train/f1score_label_\u8a55\u4fa1": 0.0, "train/accuracy_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.9099663496017456, "train/presicion_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.07024793326854706, "train/recall_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.015057573094964027, "train/f1score_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.024799415841698647, "train/accuracy_label_\u540c\u610f": 0.9509764313697815, "train/presicion_label_\u540c\u610f": 0.0, "train/recall_label_\u540c\u610f": 0.0, "train/f1score_label_\u540c\u610f": 0.0, "train/accuracy_label_\u7d0d\u5f97": 0.95252525806427, "train/presicion_label_\u7d0d\u5f97": 0.025078369304537773, "train/recall_label_\u7d0d\u5f97": 0.019900497049093246, "train/f1score_label_\u7d0d\u5f97": 0.022191401571035385, "train/accuracy_label_\u9a5a\u304d": 0.9628282785415649, "train/presicion_label_\u9a5a\u304d": 0.027027027681469917, "train/recall_label_\u9a5a\u304d": 0.017543859779834747, "train/f1score_label_\u9a5a\u304d": 0.021276595070958138, "train/accuracy_label_\u305d\u306e\u4ed6": 0.8892256021499634, "train/presicion_label_\u305d\u306e\u4ed6": 0.07564575970172882, "train/recall_label_\u305d\u306e\u4ed6": 0.03459915518760681, "train/f1score_label_\u305d\u306e\u4ed6": 0.04748118296265602, "test_loss": 0.6857895255088806, "test/multilabelaccuracy": 0.8839911818504333, "test/multilabelprecision": 0.08332628756761551, "test/multilabelrecall": 0.1094479039311409, "test/multilabelf1score": 0.09461730718612671, "test/multilabelmatthewscorrcoef": 0.4906275272369385, "_wandb": {"runtime": 339}}