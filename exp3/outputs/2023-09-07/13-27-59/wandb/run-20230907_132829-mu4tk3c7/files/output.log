/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:398: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
Downloading (â€¦)solve/main/vocab.txt: 100% 15.7k/15.7k [00:00<00:00, 22.4MB/s]
Downloading (â€¦)okenizer_config.json: 100% 110/110 [00:00<00:00, 299kB/s]
Downloading (â€¦)lve/main/config.json: 100% 478/478 [00:00<00:00, 1.27MB/s]
test:
    Unnamed: 0  ... binary
0          205  ...      1
1          206  ...      1
2          207  ...      1
3          208  ...      1
4          209  ...      1
5          210  ...      1
6          211  ...      1
7          212  ...      1
8          213  ...      1
9          214  ...      1
10         215  ...      1
11         216  ...      0
12         217  ...      0
13         218  ...      0
14         219  ...      1
15         220  ...      1
16         221  ...      1
17         222  ...      1
18         223  ...      1
19         224  ...      1
20         225  ...      0
21         226  ...      0
22         227  ...      0
23         228  ...      1
24         229  ...      1
25         230  ...      1
26         231  ...      1
27         232  ...      1
28         233  ...      1
29         234  ...      1
30         235  ...      0
31         236  ...      0
32         237  ...      1
33         238  ...      1
34         239  ...      1
35         240  ...      1
36         241  ...      1
37         242  ...      1
38         243  ...      1
39         244  ...      1
40         245  ...      1
41         246  ...      1
42         247  ...      1
43         248  ...      1
44         249  ...      1
45         250  ...      1
46         251  ...      1
47         252  ...      1
48         253  ...      1
49         254  ...      0
[50 rows x 3 columns]





Downloading pytorch_model.bin: 100% 359M/359M [00:09<00:00, 36.2MB/s]
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m   [22mâ”ƒ[1m Name         [22mâ”ƒ[1m Type             [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0 â”‚ bert         â”‚ BertModel        â”‚ 89.1 M â”‚
â”‚ 1 â”‚ hidden_layer â”‚ Linear           â”‚  6.2 K â”‚
â”‚ 2 â”‚ layer        â”‚ Linear           â”‚      9 â”‚
â”‚ 3 â”‚ criterion    â”‚ BCELoss          â”‚      0 â”‚
â”‚ 4 â”‚ metrics      â”‚ MetricCollection â”‚      0 â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 7.1 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 89.1 M
[1mTotal estimated model params size (MB)[22m: 356

[?25l
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:281:
PossibleUserWarning: The number of training batches (6) is smaller than the
logging interval Trainer(log_every_n_steps=50). Set a lower value for
log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
[37mEpoch 0/3 [39m [35mâ”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m1/6[39m [37m0:01:06 â€¢ -:--:--[39m [37m0.00it/s[39m [37mv_num: k3c7        





                                                             [37mtrain/loss: 0.669  

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”[39m [37m1/2[39m [37m0:00:52 â€¢ -:--:--[39m [37m0.00it/s






                                                             [37mtrain/loss: 0.541  
[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”[39m [37m1/2[39m [37m0:00:50 â€¢ -:--:--[39m [37m0.00it/s







                                                             [37mtrain/loss: 0.458  
[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”[39m [37m1/2[39m [37m0:00:51 â€¢ -:--:--[39m [37m0.00it/s







                                                             [37mtrain/loss: 0.412  

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”[39m [37m1/2[39m [37m0:00:51 â€¢ -:--:--[39m [37m0.00it/s
Epoch 3, global step 24: 'val_loss' reached 0.54386 (best 0.54386), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp3/outputs/2023-09-07/13-27-59/wandb/run-20230907_132829-mu4tk3c7/files/checkpoints/epoch=3.ckpt' as top 1
`Trainer.fit` stopped: `max_epochs=4` reached.

å®Ÿè¡Œæ¸ˆã¿
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m        Test metric        [22mâ”ƒ[1m       DataLoader 0        [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m         test_loss         [39mâ”‚[35m    0.5223554968833923     [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m2/2[39m [37m0:01:22 â€¢ 0:00:00[39m [37m0.03it/s
[?25h