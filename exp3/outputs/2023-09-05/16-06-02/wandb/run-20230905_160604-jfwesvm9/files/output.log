/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:398: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
test:
    Unnamed: 0  ... binary
0          205  ...      1
1          206  ...      1
2          207  ...      1
3          208  ...      1
4          209  ...      1
5          210  ...      1
6          211  ...      1
7          212  ...      1
8          213  ...      1
9          214  ...      1
10         215  ...      1
11         216  ...      0
12         217  ...      0
13         218  ...      0
14         219  ...      1
15         220  ...      1
16         221  ...      1
17         222  ...      1
18         223  ...      1
19         224  ...      1
20         225  ...      0
21         226  ...      0
22         227  ...      0
23         228  ...      1
24         229  ...      1
25         230  ...      1
26         231  ...      1
27         232  ...      1
28         233  ...      1
29         234  ...      1
30         235  ...      0
31         236  ...      0
32         237  ...      1
33         238  ...      1
34         239  ...      1
35         240  ...      1
36         241  ...      1
37         242  ...      1
38         243  ...      1
39         244  ...      1
40         245  ...      1
41         246  ...      1
42         247  ...      1
43         248  ...      1
44         249  ...      1
45         250  ...      1
46         251  ...      1
47         252  ...      1
48         253  ...      1
49         254  ...      0
[50 rows x 3 columns]
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m   [22mâ”ƒ[1m Name         [22mâ”ƒ[1m Type             [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0 â”‚ bert         â”‚ BertModel        â”‚ 89.1 M â”‚
â”‚ 1 â”‚ hidden_layer â”‚ Linear           â”‚ 49.2 K â”‚
â”‚ 2 â”‚ layer        â”‚ Linear           â”‚     65 â”‚
â”‚ 3 â”‚ criterion    â”‚ BCELoss          â”‚      0 â”‚
â”‚ 4 â”‚ metrics      â”‚ MetricCollection â”‚      0 â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 7.1 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 89.2 M
[1mTotal estimated model params size (MB)[22m: 356
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:281:
PossibleUserWarning: The number of training batches (11) is smaller than the
logging interval Trainer(log_every_n_steps=50). Set a lower value for
log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
[37mEpoch 0/3 [39m [35mâ”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m1/11[39m [37m0:00:54 â€¢ -:--:--[39m [37m0.00it/s[39m [37mv_num: svm9       










                                                              [37mtrain/loss: 0.471 

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”[39m [37m2/3  [39m [37m0:01:24 â€¢ -:--:--[39m [37m0.00it/s












                                                              [37mtrain/loss: 0.356 


[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”[39m [37m2/3  [39m [37m0:01:19 â€¢ -:--:--[39m [37m0.00it/s











                                                              [37mtrain/loss: 0.256 


[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”[39m [37m2/3  [39m [37m0:01:18 â€¢ -:--:--[39m [37m0.00it/s











                                                              [37mtrain/loss: 0.231 

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”[39m [37m2/3  [39m [37m0:01:21 â€¢ -:--:--[39m [37m0.00it/s
Epoch 3, global step 44: 'val_loss' was not in top 1

[?25h