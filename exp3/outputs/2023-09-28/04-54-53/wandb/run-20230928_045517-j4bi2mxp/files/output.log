/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:398: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
  rank_zero_warn(
Downloading (‚Ä¶)solve/main/vocab.txt: 100% 15.7k/15.7k [00:00<00:00, 15.4MB/s]
Downloading (‚Ä¶)okenizer_config.json: 100% 110/110 [00:00<00:00, 121kB/s]
Downloading (‚Ä¶)lve/main/config.json: 100% 478/478 [00:00<00:00, 477kB/s]
Downloading pytorch_model.bin: 100% 359M/359M [00:01<00:00, 271MB/s]
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
‚îè‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î≥‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì
‚îÉ[1m   [22m‚îÉ[1m Name         [22m‚îÉ[1m Type             [22m‚îÉ[1m Params [22m‚îÉ
‚î°‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚ïá‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚î©
‚îÇ 0 ‚îÇ bert         ‚îÇ BertModel        ‚îÇ 89.1 M ‚îÇ
‚îÇ 1 ‚îÇ hidden_layer ‚îÇ Linear           ‚îÇ  6.2 K ‚îÇ
‚îÇ 2 ‚îÇ layer        ‚îÇ Linear           ‚îÇ      9 ‚îÇ
‚îÇ 3 ‚îÇ criterion    ‚îÇ BCELoss          ‚îÇ      0 ‚îÇ
‚îÇ 4 ‚îÇ metrics      ‚îÇ MetricCollection ‚îÇ      0 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
[1mTrainable params[22m: 7.1 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 89.1 M
[1mTotal estimated model params size (MB)[22m: 356
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:281:
PossibleUserWarning: The number of training batches (6) is smaller than the
logging interval Trainer(log_every_n_steps=50). Set a lower value for
log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
[37mEpoch 0/3 [39m [35m‚îÅ‚îÅ‚îÅ[90m‚ï∫‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [37m1/6[39m [37m0:01:48 ‚Ä¢ -:--:--[39m [37m0.00it/s[39m [37mv_num: 2mxp        





                                                             [37mtrain/loss: 0.608  
[37mValidation[39m [35m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[90m‚ï∫‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [37m1/2[39m [37m0:01:25 ‚Ä¢ -:--:--[39m [37m0.00it/s
        [0.5591],
        [0.5975],
        [0.5789],
        [0.5743],
        [0.5737],
        [0.5538],
        [0.5841],
        [0.5483],
        [0.5703],
        [0.5717],
        [0.5431],
        [0.5894],
        [0.5604],
        [0.5717],
        [0.5650],
        [0.5678],
        [0.5742],
        [0.5858],
        [0.5690],
        [0.5866],
        [0.5621],
        [0.5659],
        [0.5452],
        [0.5829],
        [0.5755],
        [0.5621],
        [0.5664],
        [0.5330],
        [0.5633],
        [0.5551]], grad_fn=<SigmoidBackward0>), tensor([[0.5807],
        [0.5843],
        [0.5802],
        [0.5794],
        [0.5734],
        [0.5776],
        [0.5834],
        [0.5871],
        [0.5562],
        [0.5560],
        [0.5667],
        [0.5734],
        [0.5585],
        [0.5685],
        [0.5601],
        [0.5589],
        [0.6148],
        [0.5958],
        [0.5769],
        [0.6010],
        [0.5728],
        [0.5619],
        [0.5704],
        [0.5693],
        [0.5855],
        [0.5692],
        [0.5567],
        [0.5920],
        [0.6164],
        [0.5724],
        [0.5705],
        [0.5590]], grad_fn=<SigmoidBackward0>), tensor([[0.5691],
        [0.5869],
        [0.5734],
        [0.5601],
        [0.6000],
        [0.5857],
        [0.5812],
        [0.5769],
        [0.6045],
        [0.5634],
        [0.5620],
        [0.5734],
        [0.5675],
        [0.5770],
        [0.5649],
        [0.5890],
        [0.5670],
        [0.5816],
        [0.5608],
        [0.5757],
        [0.5735],
        [0.6117],
        [0.5777],
        [0.5672],
        [0.5563],
        [0.5674],
        [0.5786],
        [0.5687],
        [0.5733],
        [0.5784],
        [0.5814],
        [0.5758]], grad_fn=<SigmoidBackward0>), tensor([[0.5865],
        [0.5865],
        [0.5830],
        [0.5984],
        [0.5797],
        [0.5850],
        [0.5822],
        [0.5695],
        [0.5907],
        [0.5832],
        [0.5774],
        [0.5755],
        [0.5907],
        [0.6052],
        [0.5978],
        [0.5965],
        [0.5946],
        [0.5764],
        [0.5954],
        [0.5849],
        [0.6040],
        [0.5779],
        [0.5781],
        [0.5945],
        [0.5739],
        [0.6042],
        [0.5784],
        [0.5750],
        [0.6043],
        [0.5815],
        [0.5755],
        [0.5858]], grad_fn=<SigmoidBackward0>), tensor([[0.5803],
        [0.5967],
        [0.5941],
        [0.5822],
        [0.5983],
        [0.5842],
        [0.6134],
        [0.5933],
        [0.5872],
        [0.5985],
        [0.6008],
        [0.5878],
        [0.5693],
        [0.6440],
        [0.5782],
        [0.6041],
        [0.5961],
        [0.5819],
        [0.5934],
        [0.6074],
        [0.6014],
        [0.5904],
        [0.5954],
        [0.5836],
        [0.5784],
        [0.6045],
        [0.5770],
        [0.6107],
        [0.6259],
        [0.5868],
        [0.6095],
        [0.5803]], grad_fn=<SigmoidBackward0>), tensor([[0.6000],
        [0.6487],
        [0.6223]], grad_fn=<SigmoidBackward0>)]
tensor([[0.5489],
        [0.5671],
        [0.5591],
        [0.5975],
        [0.5789],
        [0.5743],
        [0.5737],
        [0.5538],
        [0.5841],
        [0.5483],
        [0.5703],
        [0.5717],
        [0.5431],
        [0.5894],
        [0.5604],
        [0.5717],
        [0.5650],
        [0.5678],
        [0.5742],
        [0.5858],
        [0.5690],
        [0.5866],
        [0.5621],
        [0.5659],
        [0.5452],
        [0.5829],
        [0.5755],
        [0.5621],
        [0.5664],
        [0.5330],
        [0.5633],
        [0.5551],
        [0.5807],
        [0.5843],
        [0.5802],
        [0.5794],
        [0.5734],
        [0.5776],
        [0.5834],
        [0.5871],
        [0.5562],
        [0.5560],
        [0.5667],
        [0.5734],
        [0.5585],
        [0.5685],
        [0.5601],
        [0.5589],
        [0.6148],
        [0.5958],
        [0.5769],
        [0.6010],
        [0.5728],
        [0.5619],
        [0.5704],
        [0.5693],
        [0.5855],
        [0.5692],
        [0.5567],
        [0.5920],
        [0.6164],
        [0.5724],
        [0.5705],
        [0.5590],
        [0.5691],
        [0.5869],
        [0.5734],
        [0.5601],
        [0.6000],
        [0.5857],
        [0.5812],
        [0.5769],
        [0.6045],
        [0.5634],
        [0.5620],
        [0.5734],
        [0.5675],
        [0.5770],
        [0.5649],
        [0.5890],
        [0.5670],
        [0.5816],
        [0.5608],
        [0.5757],
        [0.5735],
        [0.6117],
        [0.5777],
        [0.5672],
        [0.5563],
        [0.5674],
        [0.5786],
        [0.5687],
        [0.5733],
        [0.5784],
        [0.5814],
        [0.5758],
        [0.5865],
        [0.5865],
        [0.5830],
        [0.5984],
        [0.5797],
        [0.5850],
        [0.5822],
        [0.5695],
        [0.5907],
        [0.5832],
        [0.5774],
        [0.5755],
        [0.5907],
        [0.6052],
        [0.5978],
        [0.5965],
        [0.5946],
        [0.5764],
        [0.5954],
        [0.5849],
        [0.6040],
        [0.5779],
        [0.5781],
        [0.5945],
        [0.5739],
        [0.6042],
        [0.5784],
        [0.5750],
        [0.6043],
        [0.5815],
        [0.5755],
        [0.5858],
        [0.5803],
        [0.5967],
        [0.5941],
        [0.5822],
        [0.5983],
        [0.5842],
        [0.6134],
        [0.5933],
        [0.5872],
        [0.5985],
        [0.6008],
        [0.5878],
        [0.5693],
        [0.6440],
        [0.5782],
        [0.6041],
        [0.5961],
        [0.5819],
        [0.5934],
        [0.6074],
        [0.6014],
        [0.5904],
        [0.5954],
        [0.5836],
        [0.5784],
        [0.6045],
        [0.5770],
        [0.6107],
        [0.6259],
        [0.5868],
        [0.6095],
        [0.5803],
        [0.6000],
        [0.6487],
        [0.6223]], grad_fn=<CatBackward0>)
tensor([0.5489, 0.5671, 0.5591, 0.5975, 0.5789, 0.5743, 0.5737, 0.5538, 0.5841,
        0.5483, 0.5703, 0.5717, 0.5431, 0.5894, 0.5604, 0.5717, 0.5650, 0.5678,
        0.5742, 0.5858, 0.5690, 0.5866, 0.5621, 0.5659, 0.5452, 0.5829, 0.5755,
        0.5621, 0.5664, 0.5330, 0.5633, 0.5551, 0.5807, 0.5843, 0.5802, 0.5794,
        0.5734, 0.5776, 0.5834, 0.5871, 0.5562, 0.5560, 0.5667, 0.5734, 0.5585,
        0.5685, 0.5601, 0.5589, 0.6148, 0.5958, 0.5769, 0.6010, 0.5728, 0.5619,
        0.5704, 0.5693, 0.5855, 0.5692, 0.5567, 0.5920, 0.6164, 0.5724, 0.5705,
        0.5590, 0.5691, 0.5869, 0.5734, 0.5601, 0.6000, 0.5857, 0.5812, 0.5769,
        0.6045, 0.5634, 0.5620, 0.5734, 0.5675, 0.5770, 0.5649, 0.5890, 0.5670,
        0.5816, 0.5608, 0.5757, 0.5735, 0.6117, 0.5777, 0.5672, 0.5563, 0.5674,
        0.5786, 0.5687, 0.5733, 0.5784, 0.5814, 0.5758, 0.5865, 0.5865, 0.5830,
        0.5984, 0.5797, 0.5850, 0.5822, 0.5695, 0.5907, 0.5832, 0.5774, 0.5755,
        0.5907, 0.6052, 0.5978, 0.5965, 0.5946, 0.5764, 0.5954, 0.5849, 0.6040,
        0.5779, 0.5781, 0.5945, 0.5739, 0.6042, 0.5784, 0.5750, 0.6043, 0.5815,
        0.5755, 0.5858, 0.5803, 0.5967, 0.5941, 0.5822, 0.5983, 0.5842, 0.6134,
        0.5933, 0.5872, 0.5985, 0.6008, 0.5878, 0.5693, 0.6440, 0.5782, 0.6041,
        0.5961, 0.5819, 0.5934, 0.6074, 0.6014, 0.5904, 0.5954, 0.5836, 0.5784,
        0.6045, 0.5770, 0.6107, 0.6259, 0.5868, 0.6095, 0.5803, 0.6000, 0.6487,
        0.6223], grad_fn=<SqueezeBackward0>)
[37mEpoch 0/3 [39m [35m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[39m [37m6/6[39m [37m0:09:32 ‚Ä¢ 0:00:00[39m [37m0.10it/s[39m [37mv_num: 2mxp        
                                                             [37mtrain/loss: 0.608  
                                                             [37mtrain/loss: 0.608  
                                                             [37mtrain/loss: 0.608  
                                                             [37mtrain/loss: 0.608  
                                                             [37mtrain/loss: 0.608  
[rank: 0] Received SIGTERM: 15
[rank: 0] Received SIGTERM: 15
                                                             [37mtrain/loss: 0.608  