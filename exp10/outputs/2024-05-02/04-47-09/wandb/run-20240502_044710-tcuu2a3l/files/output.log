/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:391: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
[32m[I 2024-05-02 04:47:12,025][39m A new study created in memory with name: no-name-fc556598-1948-4316-a6a2-c5372d393633
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type             [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ bert                        â”‚ BertModel        â”‚ 89.1 M â”‚
â”‚ 1  â”‚ classifiers                 â”‚ ModuleList       â”‚  4.7 M â”‚
â”‚ 2  â”‚ hidden_layer1               â”‚ ModuleList       â”‚  4.4 M â”‚
â”‚ 3  â”‚ hidden_layer2               â”‚ ModuleList       â”‚ 11.3 K â”‚
â”‚ 4  â”‚ sigmoid                     â”‚ Sigmoid          â”‚      0 â”‚
â”‚ 5  â”‚ criterion                   â”‚ Focal_Loss       â”‚      0 â”‚
â”‚ 6  â”‚ metrics                     â”‚ MetricCollection â”‚      0 â”‚
â”‚ 7  â”‚ metrics_per_label_accuracy  â”‚ MetricCollection â”‚      0 â”‚
â”‚ 8  â”‚ metrics_per_label_precision â”‚ MetricCollection â”‚      0 â”‚
â”‚ 9  â”‚ metrics_per_label_recall    â”‚ MetricCollection â”‚      0 â”‚
â”‚ 10 â”‚ metrics_per_label_f1score   â”‚ MetricCollection â”‚      0 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 16.2 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 98.2 M
[1mTotal estimated model params size (MB)[22m: 392
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelAccuracy
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelPrecision
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelRecall
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelF1Score
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelMatthewsCorrCoef
NO
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of
training batches (31) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a
lower value for log_every_n_steps if you want to see logs for the training epoch.
[37mEpoch 0/3 [39m [35mâ”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m10/31[39m [37m0:00:01 â€¢ 0:00:03[39m [37m7.10it/s[39m [37mv_num: 2a3l train/loss:     
                                                                        [37m0.087                       
MultilabelAccuracy
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelPrecision
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelRecall
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelF1Score
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelMatthewsCorrCoef
NO
torch.Size([1000, 16])
[37mEpoch 0/3 [39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m31/31[39m [37m0:00:04 â€¢ 0:00:00[39m [37m6.55it/s[39m [37mv_num: 2a3l train/loss:     
                                                                        [37m0.087                       


'MultilabelMatthewsCorrCoef'])
MultilabelAccuracy
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelPrecision
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelRecall
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelF1Score
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelMatthewsCorrCoef
NO
torch.Size([1000, 16])
Epoch 1/3  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m31/31[39m [37m0:00:05 â€¢ 0:00:00[39m [37m5.66it/s[39m [37mv_num: 2a3l train/loss:     
                                                                        [37m0.087                       

'MultilabelMatthewsCorrCoef'])
MultilabelAccuracy
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelPrecision
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelRecall
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelF1Score
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelMatthewsCorrCoef
NO
torch.Size([1000, 16])
Epoch 2/3  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m31/31[39m [37m0:00:05 â€¢ 0:00:00[39m [37m5.71it/s[39m [37mv_num: 2a3l train/loss:     
                                                                        [37m0.086                       
Epoch 2, global step 93: 'val_loss' reached 0.08565 (best 0.08565), saving model to '/content/murata_labo_exp/murata_labo_exp_src/exp10/outputs/2024-05-02/04-47-09/wandb/run-20240502_044710-tcuu2a3l/files/checkpoints/epoch=2.ckpt' as top 1
                                                                        [37m0.087                       
                                                                        [37m0.087                       
                                                                        [37m0.085                       
                                                                        [37m0.085                       

Epoch 3, global step 124: 'val_loss' reached 0.08556 (best 0.08556), saving model to '/content/murata_labo_exp/murata_labo_exp_src/exp10/outputs/2024-05-02/04-47-09/wandb/run-20240502_044710-tcuu2a3l/files/checkpoints/epoch=3.ckpt' as top 1
`Trainer.fit` stopped: `max_epochs=4` reached.
[32m[I 2024-05-02 04:48:00,056][39m Trial 0 finished with value: 1.0 and parameters: {'batch_size': 33, 'epoch': 7, 'hidden_size': 386, 'hidden_size2': 706, 'focal_loss_gamma': 3}. Best is trial 0 with value: 1.0.
[?25h
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /content/murata_labo_exp/murata_labo_exp_src/exp10/outputs/2024-05-02/04-47-09/wandb/run-20240502_044710-tcuu2a3l/files/checkpoints exists and is not empty.
[?25hâ”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type             [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ bert                        â”‚ BertModel        â”‚ 89.1 M â”‚
â”‚ 1  â”‚ classifiers                 â”‚ ModuleList       â”‚  2.4 M â”‚
â”‚ 2  â”‚ hidden_layer1               â”‚ ModuleList       â”‚  1.5 M â”‚
â”‚ 3  â”‚ hidden_layer2               â”‚ ModuleList       â”‚  7.7 K â”‚
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
â”‚ 5  â”‚ criterion                   â”‚ Focal_Loss       â”‚      0 â”‚
â”‚ 6  â”‚ metrics                     â”‚ MetricCollection â”‚      0 â”‚
â”‚ 7  â”‚ metrics_per_label_accuracy  â”‚ MetricCollection â”‚      0 â”‚
â”‚ 8  â”‚ metrics_per_label_precision â”‚ MetricCollection â”‚      0 â”‚
â”‚ 9  â”‚ metrics_per_label_recall    â”‚ MetricCollection â”‚      0 â”‚
â”‚ 10 â”‚ metrics_per_label_f1score   â”‚ MetricCollection â”‚      0 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 11.1 M
[1mNon-trainable params[22m: 82.0 M
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
[1mTotal estimated model params size (MB)[22m: 372
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelAccuracy
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelPrecision
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelRecall
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelF1Score
NO
dict_keys(['MultilabelAccuracy', 'MultilabelPrecision', 'MultilabelRecall', 'MultilabelF1Score',
'MultilabelMatthewsCorrCoef'])
MultilabelMatthewsCorrCoef
NO
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of
training batches (20) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a
lower value for log_every_n_steps if you want to see logs for the training epoch.
[37mEpoch 0/3 [39m [35mâ”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m4/20[39m [37m0:00:01 â€¢ 0:00:06[39m [37m3.05it/s[39m [37mv_num: 2a3l train/loss:     
                                                                        [37m0.177                       
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:298: The number of
NO
NO
Epoch 0, global step 20: 'val_loss' reached 0.17073 (best 0.17073), saving model to '/content/murata_labo_exp/murata_labo_exp_src/exp10/outputs/2024-05-02/04-47-09/wandb/run-20240502_044710-tcuu2a3l/files/checkpoints/epoch=0.ckpt' as top 1
NO
NO
NO
NO
NO
Epoch 1, global step 40: 'val_loss' reached 0.16875 (best 0.16875), saving model to '/content/murata_labo_exp/murata_labo_exp_src/exp10/outputs/2024-05-02/04-47-09/wandb/run-20240502_044710-tcuu2a3l/files/checkpoints/epoch=1.ckpt' as top 1
NO
NO
NO
NO
Epoch 2, global step 60: 'val_loss' reached 0.16740 (best 0.16740), saving model to '/content/murata_labo_exp/murata_labo_exp_src/exp10/outputs/2024-05-02/04-47-09/wandb/run-20240502_044710-tcuu2a3l/files/checkpoints/epoch=2.ckpt' as top 1
NO
NO
NO
[32m[I 2024-05-02 04:48:43,907][39m Trial 1 finished with value: 1.0 and parameters: {'batch_size': 52, 'epoch': 8, 'hidden_size': 198, 'hidden_size2': 478, 'focal_loss_gamma': 2}. Best is trial 0 with value: 1.0.
[33m[W 2024-05-02 04:48:43,918][39m Trial 2 failed with parameters: {'batch_size': 63, 'epoch': 6, 'hidden_size': 441, 'hidden_size2': 600, 'focal_loss_gamma': 3} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/usr/lib/python3.10/genericpath.py", line 42, in isdir
    st = os.stat(s)
FileNotFoundError: [Errno 2] No such file or directory: 'cl-tohoku/bert-base-japanese-char-whole-word-masking'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/content/murata_labo_exp/murata_labo_exp_src/exp10/main.py", line 636, in objective
    data_module = CreateDataModule(
  File "/content/murata_labo_exp/murata_labo_exp_src/exp10/main.py", line 88, in __init__
    self.tokenizer = BertJapaneseTokenizer.from_pretrained(pretrained_model)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 1939, in from_pretrained
    is_local = os.path.isdir(pretrained_model_name_or_path)
  File "/usr/lib/python3.10/genericpath.py", line 42, in isdir
    st = os.stat(s)
KeyboardInterrupt
[33m[W 2024-05-02 04:48:43,926][39m Trial 2 failed with value None.
Traceback (most recent call last):
  File "/usr/lib/python3.10/genericpath.py", line 42, in isdir
    st = os.stat(s)
FileNotFoundError: [Errno 2] No such file or directory: 'cl-tohoku/bert-base-japanese-char-whole-word-masking'
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/content/murata_labo_exp/murata_labo_exp_src/exp10/main.py", line 713, in <module>
    main()
  File "/usr/local/lib/python3.10/dist-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/usr/local/lib/python3.10/dist-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/usr/local/lib/python3.10/dist-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/content/murata_labo_exp/murata_labo_exp_src/exp10/main.py", line 682, in main
    study.optimize(objective,n_trials=10)
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/study.py", line 451, in optimize
    _optimize(
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 62, in _optimize
    _optimize_sequential(
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 159, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 247, in _run_trial
    raise func_err
  File "/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py", line 196, in _run_trial
    value_or_values = func(trial)
  File "/content/murata_labo_exp/murata_labo_exp_src/exp10/main.py", line 636, in objective
    data_module = CreateDataModule(
  File "/content/murata_labo_exp/murata_labo_exp_src/exp10/main.py", line 88, in __init__
    self.tokenizer = BertJapaneseTokenizer.from_pretrained(pretrained_model)
  File "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py", line 1939, in from_pretrained
    is_local = os.path.isdir(pretrained_model_name_or_path)
  File "/usr/lib/python3.10/genericpath.py", line 42, in isdir
    st = os.stat(s)
KeyboardInterrupt
NO