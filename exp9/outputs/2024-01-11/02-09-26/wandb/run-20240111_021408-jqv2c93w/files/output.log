
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
tokenizer_config.json: 100% 110/110 [00:00<00:00, 303kB/s]
vocab.txt: 100% 15.7k/15.7k [00:00<00:00, 32.7MB/s]
config.json: 100% 478/478 [00:00<00:00, 1.55MB/s]





pytorch_model.bin: 100% 359M/359M [00:10<00:00, 33.9MB/s]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type             [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ bert                        â”‚ BertModel        â”‚ 89.1 M â”‚
â”‚ 1  â”‚ classifiers                 â”‚ ModuleList       â”‚  6.3 M â”‚
â”‚ 2  â”‚ hidden_layer1               â”‚ ModuleList       â”‚  2.1 M â”‚
â”‚ 3  â”‚ hidden_layer2               â”‚ ModuleList       â”‚  2.1 K â”‚
â”‚ 4  â”‚ sigmoid                     â”‚ Sigmoid          â”‚      0 â”‚
â”‚ 5  â”‚ criterion                   â”‚ BCELoss          â”‚      0 â”‚
â”‚ 6  â”‚ metrics                     â”‚ MetricCollection â”‚      0 â”‚
â”‚ 7  â”‚ metrics_per_label_accuracy  â”‚ MetricCollection â”‚      0 â”‚
â”‚ 8  â”‚ metrics_per_label_precision â”‚ MetricCollection â”‚      0 â”‚
â”‚ 9  â”‚ metrics_per_label_recall    â”‚ MetricCollection â”‚      0 â”‚
â”‚ 10 â”‚ metrics_per_label_f1score   â”‚ MetricCollection â”‚      0 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 15.5 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 97.5 M
[1mTotal estimated model params size (MB)[22m: 390
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of
training batches (3) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower
value for log_every_n_steps if you want to see logs for the training epoch.
[37mEpoch 0/7 [39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”[39m [37m2/3[39m [37m0:00:04 â€¢ 0:00:01[39m [37m40.32it/s[39m [37mv_num: c93w train/loss:     

                                                                        [37m0.693                       



Epoch 1/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/3[39m [37m0:00:08 â€¢ 0:00:00[39m [37m0.23it/s[39m [37mv_num: c93w train/loss: 0.685



Epoch 2/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/3[39m [37m0:00:09 â€¢ 0:00:00[39m [37m0.23it/s[39m [37mv_num: c93w train/loss: 0.676




Epoch 3/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/3[39m [37m0:00:09 â€¢ 0:00:00[39m [37m0.23it/s[39m [37mv_num: c93w train/loss: 0.685



Epoch 4/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/3[39m [37m0:00:09 â€¢ 0:00:00[39m [37m0.22it/s[39m [37mv_num: c93w train/loss: 0.677



Epoch 5/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/3[39m [37m0:00:09 â€¢ 0:00:00[39m [37m0.22it/s[39m [37mv_num: c93w train/loss: 0.670



Epoch 6/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/3[39m [37m0:00:09 â€¢ 0:00:00[39m [37m0.22it/s[39m [37mv_num: c93w train/loss: 0.668



Epoch 7/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/3[39m [37m0:00:09 â€¢ 0:00:00[39m [37m0.21it/s[39m [37mv_num: c93w train/loss: 0.673
Epoch 7, global step 24: 'val_loss' reached 0.67250 (best 0.67250), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp9/outputs/2024-01-11/02-09-26/wandb/run-20240111_021408-jqv2c93w/files/checkpoints/epoch=7.ckpt' as top 1
`Trainer.fit` stopped: `max_epochs=8` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m           Test metric           [22mâ”ƒ[1m          DataLoader 0           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m     test/multilabelaccuracy     [39mâ”‚[35m       0.6638199090957642        [39mâ”‚
â”‚[36m     test/multilabelf1score      [39mâ”‚[35m       0.4292103052139282        [39mâ”‚
â”‚[36m test/multilabelmatthewscorrcoef [39mâ”‚[35m       0.33039629459381104       [39mâ”‚
â”‚[36m    test/multilabelprecision     [39mâ”‚[35m       0.4835689067840576        [39mâ”‚
â”‚[36m      test/multilabelrecall      [39mâ”‚[35m       0.47488418221473694       [39mâ”‚
â”‚[36m            test_loss            [39mâ”‚[35m       0.6716439723968506        [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/3[39m [37m0:00:00 â€¢ 0:00:00[39m [37m73.26it/s
[?25h