{"val_loss": 0.2469848096370697, "val/multilabelaccuracy": 0.5326923131942749, "val/multilabelprecision": 0.25016024708747864, "val/multilabelrecall": 0.40909090638160706, "val/multilabelf1score": 0.30295610427856445, "val/multilabelmatthewscorrcoef": 0.07423626631498337, "val/accuracy_label_\u3042\u3044\u3065\u3061": 0.07692307978868484, "val/presicion_label_\u3042\u3044\u3065\u3061": 0.0, "val/recall_label_\u3042\u3044\u3065\u3061": 0.0, "val/f1score_label_\u3042\u3044\u3065\u3061": 0.0, "val/accuracy_label_\u611f\u5fc3": 0.8615384697914124, "val/presicion_label_\u611f\u5fc3": 0.8615384697914124, "val/recall_label_\u611f\u5fc3": 1.0, "val/f1score_label_\u611f\u5fc3": 0.9256198406219482, "val/accuracy_label_\u8a55\u4fa1": 0.6153846383094788, "val/presicion_label_\u8a55\u4fa1": 0.0, "val/recall_label_\u8a55\u4fa1": 0.0, "val/f1score_label_\u8a55\u4fa1": 0.0, "val/accuracy_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.4000000059604645, "val/presicion_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "val/recall_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "val/f1score_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "val/accuracy_label_\u540c\u610f": 0.4615384638309479, "val/presicion_label_\u540c\u610f": 0.4166666567325592, "val/recall_label_\u540c\u610f": 1.0, "val/f1score_label_\u540c\u610f": 0.5882353186607361, "val/accuracy_label_\u7d0d\u5f97": 0.6307692527770996, "val/presicion_label_\u7d0d\u5f97": 0.0, "val/recall_label_\u7d0d\u5f97": 0.0, "val/f1score_label_\u7d0d\u5f97": 0.0, "val/accuracy_label_\u9a5a\u304d": 0.7230769395828247, "val/presicion_label_\u9a5a\u304d": 0.23076923191547394, "val/recall_label_\u9a5a\u304d": 0.27272728085517883, "val/f1score_label_\u9a5a\u304d": 0.25, "val/accuracy_label_\u305d\u306e\u4ed6": 0.4923076927661896, "val/presicion_label_\u305d\u306e\u4ed6": 0.4923076927661896, "val/recall_label_\u305d\u306e\u4ed6": 1.0, "val/f1score_label_\u305d\u306e\u4ed6": 0.6597937941551208, "epoch": 4, "trainer/global_step": 12, "_timestamp": 1704874474.4790878, "_runtime": 33.53025484085083, "_step": 8, "train_loss": 0.24765393137931824, "train/multilabelaccuracy": 0.4761672914028168, "train/multilabelprecision": 0.23577377200126648, "train/multilabelrecall": 0.3878968358039856, "train/multilabelf1score": 0.27359527349472046, "train/multilabelmatthewscorrcoef": -0.0436721034348011, "train/accuracy_label_\u3042\u3044\u3065\u3061": 0.04280155524611473, "train/presicion_label_\u3042\u3044\u3065\u3061": 0.0, "train/recall_label_\u3042\u3044\u3065\u3061": 0.0, "train/f1score_label_\u3042\u3044\u3065\u3061": 0.0, "train/accuracy_label_\u611f\u5fc3": 0.8715953230857849, "train/presicion_label_\u611f\u5fc3": 0.8715953230857849, "train/recall_label_\u611f\u5fc3": 1.0, "train/f1score_label_\u611f\u5fc3": 0.9313929080963135, "train/accuracy_label_\u8a55\u4fa1": 0.5369649529457092, "train/presicion_label_\u8a55\u4fa1": 0.1875, "train/recall_label_\u8a55\u4fa1": 0.06060606241226196, "train/f1score_label_\u8a55\u4fa1": 0.09160305559635162, "train/accuracy_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.3813229501247406, "train/presicion_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "train/recall_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "train/f1score_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.0, "train/accuracy_label_\u540c\u610f": 0.33852139115333557, "train/presicion_label_\u540c\u610f": 0.31020408868789673, "train/recall_label_\u540c\u610f": 0.9870129823684692, "train/f1score_label_\u540c\u610f": 0.47204968333244324, "train/accuracy_label_\u7d0d\u5f97": 0.6108949184417725, "train/presicion_label_\u7d0d\u5f97": 0.0, "train/recall_label_\u7d0d\u5f97": 0.0, "train/f1score_label_\u7d0d\u5f97": 0.0, "train/accuracy_label_\u9a5a\u304d": 0.533073902130127, "train/presicion_label_\u9a5a\u304d": 0.022727273404598236, "train/recall_label_\u9a5a\u304d": 0.0555555559694767, "train/f1score_label_\u9a5a\u304d": 0.032258063554763794, "train/accuracy_label_\u305d\u306e\u4ed6": 0.4941634237766266, "train/presicion_label_\u305d\u306e\u4ed6": 0.4941634237766266, "train/recall_label_\u305d\u306e\u4ed6": 1.0, "train/f1score_label_\u305d\u306e\u4ed6": 0.6614583134651184, "test_loss": 0.2469024658203125, "test/multilabelaccuracy": 0.5077639818191528, "test/multilabelprecision": 0.24581396579742432, "test/multilabelrecall": 0.3975144624710083, "test/multilabelf1score": 0.28543174266815186, "test/multilabelmatthewscorrcoef": 0.02217581495642662, "_wandb": {"runtime": 33}}