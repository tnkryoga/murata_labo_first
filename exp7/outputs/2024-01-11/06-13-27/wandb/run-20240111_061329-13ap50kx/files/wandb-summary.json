{"val_loss": 0.0043458109721541405, "val/multilabelaccuracy": 0.7299046516418457, "val/multilabelprecision": 0.3225772976875305, "val/multilabelrecall": 0.35426467657089233, "val/multilabelf1score": 0.3374614417552948, "val/multilabelmatthewscorrcoef": 0.5008816719055176, "val/accuracy_label_\u3042\u3044\u3065\u3061": 0.9564032554626465, "val/presicion_label_\u3042\u3044\u3065\u3061": 0.9553072452545166, "val/recall_label_\u3042\u3044\u3065\u3061": 1.0, "val/f1score_label_\u3042\u3044\u3065\u3061": 0.977142870426178, "val/accuracy_label_\u611f\u5fc3": 0.891008198261261, "val/presicion_label_\u611f\u5fc3": 0.9026548862457275, "val/recall_label_\u611f\u5fc3": 0.9776358008384705, "val/f1score_label_\u611f\u5fc3": 0.9386503100395203, "val/accuracy_label_\u8a55\u4fa1": 0.6376021504402161, "val/presicion_label_\u8a55\u4fa1": 0.0, "val/recall_label_\u8a55\u4fa1": 0.0, "val/f1score_label_\u8a55\u4fa1": 0.0, "val/accuracy_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.7220708727836609, "val/presicion_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.72265625, "val/recall_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.8564814925193787, "val/f1score_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.7838982939720154, "val/accuracy_label_\u540c\u610f": 0.6457765698432922, "val/presicion_label_\u540c\u610f": 0.0, "val/recall_label_\u540c\u610f": 0.0, "val/f1score_label_\u540c\u610f": 0.0, "val/accuracy_label_\u7d0d\u5f97": 0.7002725005149841, "val/presicion_label_\u7d0d\u5f97": 0.0, "val/recall_label_\u7d0d\u5f97": 0.0, "val/f1score_label_\u7d0d\u5f97": 0.0, "val/accuracy_label_\u9a5a\u304d": 0.7929155230522156, "val/presicion_label_\u9a5a\u304d": 0.0, "val/recall_label_\u9a5a\u304d": 0.0, "val/f1score_label_\u9a5a\u304d": 0.0, "val/accuracy_label_\u8a00\u3044\u63db\u3048": 0.4931880235671997, "val/presicion_label_\u8a00\u3044\u63db\u3048": 0.0, "val/recall_label_\u8a00\u3044\u63db\u3048": 0.0, "val/f1score_label_\u8a00\u3044\u63db\u3048": 0.0, "epoch": 4, "trainer/global_step": 184, "_timestamp": 1704953712.9277227, "_runtime": 103.35129070281982, "_step": 11, "train_loss": 0.0011016130447387695, "train/multilabelaccuracy": 0.7216917276382446, "train/multilabelprecision": 0.40933799743652344, "train/multilabelrecall": 0.3734898269176483, "train/multilabelf1score": 0.35167834162712097, "train/multilabelmatthewscorrcoef": 0.471329003572464, "train/accuracy_label_\u3042\u3044\u3065\u3061": 0.9536153078079224, "train/presicion_label_\u3042\u3044\u3065\u3061": 0.954325258731842, "train/recall_label_\u3042\u3044\u3065\u3061": 0.9985517859458923, "train/f1score_label_\u3042\u3044\u3065\u3061": 0.9759377241134644, "train/accuracy_label_\u611f\u5fc3": 0.8540245294570923, "train/presicion_label_\u611f\u5fc3": 0.8605149984359741, "train/recall_label_\u611f\u5fc3": 0.9844517111778259, "train/f1score_label_\u611f\u5fc3": 0.9183205962181091, "train/accuracy_label_\u8a55\u4fa1": 0.639836311340332, "train/presicion_label_\u8a55\u4fa1": 0.0, "train/recall_label_\u8a55\u4fa1": 0.0, "train/f1score_label_\u8a55\u4fa1": 0.0, "train/accuracy_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.7019099593162537, "train/presicion_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.6766467094421387, "train/recall_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.9305882453918457, "train/f1score_label_\u7e70\u308a\u8fd4\u3057\u5fdc\u7b54": 0.7835562229156494, "train/accuracy_label_\u540c\u610f": 0.6698499321937561, "train/presicion_label_\u540c\u610f": 0.3589743673801422, "train/recall_label_\u540c\u610f": 0.029598308727145195, "train/f1score_label_\u540c\u610f": 0.0546875, "train/accuracy_label_\u7d0d\u5f97": 0.7005457282066345, "train/presicion_label_\u7d0d\u5f97": 0.0, "train/recall_label_\u7d0d\u5f97": 0.0, "train/f1score_label_\u7d0d\u5f97": 0.0, "train/accuracy_label_\u9a5a\u304d": 0.7830832004547119, "train/presicion_label_\u9a5a\u304d": 0.42424243688583374, "train/recall_label_\u9a5a\u304d": 0.04472843557596207, "train/f1score_label_\u9a5a\u304d": 0.080924853682518, "train/accuracy_label_\u8a00\u3044\u63db\u3048": 0.4706684947013855, "train/presicion_label_\u8a00\u3044\u63db\u3048": 0.0, "train/recall_label_\u8a00\u3044\u63db\u3048": 0.0, "train/f1score_label_\u8a00\u3044\u63db\u3048": 0.0, "train/loss": 0.04351507127285004, "test_loss": 0.005386968143284321, "test/multilabelaccuracy": 0.734083890914917, "test/multilabelprecision": 0.3250243663787842, "test/multilabelrecall": 0.35619959235191345, "test/multilabelf1score": 0.339575856924057, "test/multilabelmatthewscorrcoef": 0.5090106129646301, "_wandb": {"runtime": 103}}