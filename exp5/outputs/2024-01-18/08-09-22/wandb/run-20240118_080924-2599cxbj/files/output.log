
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type             [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ bert                        â”‚ BertModel        â”‚ 89.1 M â”‚
â”‚ 1  â”‚ classifiers                 â”‚ ModuleList       â”‚  6.3 M â”‚
â”‚ 2  â”‚ hidden_layer1               â”‚ ModuleList       â”‚  2.1 M â”‚
â”‚ 3  â”‚ hidden_layer2               â”‚ ModuleList       â”‚  2.1 K â”‚
â”‚ 4  â”‚ sigmoid                     â”‚ Sigmoid          â”‚      0 â”‚
â”‚ 5  â”‚ criterion                   â”‚ Focal_Loss       â”‚      0 â”‚
â”‚ 6  â”‚ metrics                     â”‚ MetricCollection â”‚      0 â”‚
â”‚ 7  â”‚ metrics_per_label_accuracy  â”‚ MetricCollection â”‚      0 â”‚
â”‚ 8  â”‚ metrics_per_label_precision â”‚ MetricCollection â”‚      0 â”‚
â”‚ 9  â”‚ metrics_per_label_recall    â”‚ MetricCollection â”‚      0 â”‚
â”‚ 10 â”‚ metrics_per_label_f1score   â”‚ MetricCollection â”‚      0 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 15.5 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 97.5 M
[1mTotal estimated model params size (MB)[22m: 390
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of
training batches (46) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a
lower value for log_every_n_steps if you want to see logs for the training epoch.
[37mEpoch 0/7 [39m [35mâ”â”[90mâ•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m4/46[39m [37m0:00:01 â€¢ 0:00:10[39m [37m4.22it/s[39m [37mv_num: cxbj train/loss:     






                                                                        [37m0.131                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”[39m [37m11/12[39m [37m0:00:02 â€¢ 0:00:01[39m [37m4.46it/s
Epoch 1/7  [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/46[39m [37m0:00:00 â€¢ -:--:--[39m [37m0.00it/s[39m [37mv_num: cxbj train/loss:     






                                                                        [37m0.128                       
[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”[39m [37m9/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m4.74it/s
Epoch 1/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:15 â€¢ 0:00:00[39m [37m2.90it/s[39m [37mv_num: cxbj train/loss:     








                                                                        [37m0.120                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”[39m [37m11/12[39m [37m0:00:02 â€¢ 0:00:01[39m [37m4.45it/s
Epoch 2/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:15 â€¢ 0:00:00[39m [37m2.89it/s[39m [37mv_num: cxbj train/loss:     








                                                                        [37m0.125                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m6/12 [39m [37m0:00:00 â€¢ 0:00:02[39m [37m5.99it/s
Epoch 3, global step 184: 'val_loss' reached 0.12174 (best 0.12174), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2024-01-18/08-09-22/wandb/run-20240118_080924-2599cxbj/files/checkpoints/epoch=3.ckpt' as top 1
Epoch 3/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:15 â€¢ 0:00:00[39m [37m2.89it/s[39m [37mv_num: cxbj train/loss:     





                                                                        [37m0.119                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”[39m [37m8/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m5.00it/s
Epoch 4, global step 230: 'val_loss' reached 0.12140 (best 0.12140), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2024-01-18/08-09-22/wandb/run-20240118_080924-2599cxbj/files/checkpoints/epoch=4.ckpt' as top 1
Epoch 5/7  [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/46[39m [37m0:00:00 â€¢ -:--:--[39m [37m0.00it/s[39m [37mv_num: cxbj train/loss:     








                                                                        [37m0.121                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”[39m [37m8/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m5.01it/s
Epoch 5, global step 276: 'val_loss' reached 0.12121 (best 0.12121), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2024-01-18/08-09-22/wandb/run-20240118_080924-2599cxbj/files/checkpoints/epoch=5.ckpt' as top 1
Epoch 6/7  [90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m0/46[39m [37m0:00:00 â€¢ -:--:--[39m [37m0.00it/s[39m [37mv_num: cxbj train/loss:     







                                                                        [37m0.127                       
Epoch 6/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:15 â€¢ 0:00:00[39m [37m2.89it/s[39m [37mv_num: cxbj train/loss:     
                                                                        [37m0.127                       








                                                                        [37m0.122                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”[39m [37m11/12[39m [37m0:00:02 â€¢ 0:00:01[39m [37m4.45it/s
Epoch 7/7  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:15 â€¢ 0:00:00[39m [37m2.89it/s[39m [37mv_num: cxbj train/loss:     
                                                                        [37m0.122                       
`Trainer.fit` stopped: `max_epochs=8` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m           Test metric           [22mâ”ƒ[1m          DataLoader 0           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m  test/accuracy_label_ã‚ã„ã¥ã¡   [39mâ”‚[35m       0.9503105878829956        [39mâ”‚
â”‚[36m    test/accuracy_label_åŒæ„     [39mâ”‚[35m       0.6024844646453857        [39mâ”‚
â”‚[36m    test/accuracy_label_æ„Ÿå¿ƒ     [39mâ”‚[35m       0.8788819909095764        [39mâ”‚
â”‚[36m    test/accuracy_label_ç´å¾—     [39mâ”‚[35m       0.6397515535354614        [39mâ”‚
â”‚[36m test/accuracy_label_ç¹°ã‚Šè¿”ã—å¿œâ€¦ [39mâ”‚[35m       0.7236024737358093        [39mâ”‚
â”‚[36m  test/accuracy_label_è¨€ã„æ›ãˆ   [39mâ”‚[35m        0.590062141418457        [39mâ”‚
â”‚[36m    test/accuracy_label_è©•ä¾¡     [39mâ”‚[35m       0.6211180090904236        [39mâ”‚
â”‚[36m    test/accuracy_label_é©šã     [39mâ”‚[35m       0.8540372848510742        [39mâ”‚
â”‚[36m   test/f1score_label_ã‚ã„ã¥ã¡   [39mâ”‚[35m       0.9743589758872986        [39mâ”‚
â”‚[36m     test/f1score_label_åŒæ„     [39mâ”‚[35m       0.5923566818237305        [39mâ”‚
â”‚[36m     test/f1score_label_æ„Ÿå¿ƒ     [39mâ”‚[35m       0.9346733689308167        [39mâ”‚
â”‚[36m     test/f1score_label_ç´å¾—     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/f1score_label_ç¹°ã‚Šè¿”ã—å¿œç­” [39mâ”‚[35m       0.8157349824905396        [39mâ”‚
â”‚[36m   test/f1score_label_è¨€ã„æ›ãˆ   [39mâ”‚[35m        0.674876868724823        [39mâ”‚
â”‚[36m     test/f1score_label_è©•ä¾¡     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_é©šã     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/multilabelaccuracy     [39mâ”‚[35m       0.7325310707092285        [39mâ”‚
â”‚[36m     test/multilabelf1score      [39mâ”‚[35m       0.49900010228157043       [39mâ”‚
â”‚[36m test/multilabelmatthewscorrcoef [39mâ”‚[35m       0.4641644060611725        [39mâ”‚
â”‚[36m    test/multilabelprecision     [39mâ”‚[35m       0.44008302688598633       [39mâ”‚
â”‚[36m      test/multilabelrecall      [39mâ”‚[35m       0.5947802066802979        [39mâ”‚
â”‚[36m  test/presicion_label_ã‚ã„ã¥ã¡  [39mâ”‚[35m        0.955974817276001        [39mâ”‚
â”‚[36m    test/presicion_label_åŒæ„    [39mâ”‚[35m       0.4386792480945587        [39mâ”‚
â”‚[36m    test/presicion_label_æ„Ÿå¿ƒ    [39mâ”‚[35m       0.8801261782646179        [39mâ”‚
â”‚[36m    test/presicion_label_ç´å¾—    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/presicion_label_ç¹°ã‚Šè¿”ã— â€¦ [39mâ”‚[35m       0.6912280917167664        [39mâ”‚
â”‚[36m  test/presicion_label_è¨€ã„æ›ãˆ  [39mâ”‚[35m       0.5546558499336243        [39mâ”‚
â”‚[36m    test/presicion_label_è©•ä¾¡    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_é©šã    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m   test/recall_label_ã‚ã„ã¥ã¡    [39mâ”‚[35m       0.9934640526771545        [39mâ”‚
â”‚[36m     test/recall_label_åŒæ„      [39mâ”‚[35m       0.9117646813392639        [39mâ”‚
â”‚[36m     test/recall_label_æ„Ÿå¿ƒ      [39mâ”‚[35m       0.9964285492897034        [39mâ”‚
â”‚[36m     test/recall_label_ç´å¾—      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/recall_label_ç¹°ã‚Šè¿”ã—å¿œç­”  [39mâ”‚[35m       0.9949495196342468        [39mâ”‚
â”‚[36m   test/recall_label_è¨€ã„æ›ãˆ    [39mâ”‚[35m       0.8616352081298828        [39mâ”‚
â”‚[36m     test/recall_label_è©•ä¾¡      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_é©šã      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m            test_loss            [39mâ”‚[35m       0.12123025208711624       [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m11/11[39m [37m0:00:02 â€¢ 0:00:00[39m [37m4.34it/s
[?25h