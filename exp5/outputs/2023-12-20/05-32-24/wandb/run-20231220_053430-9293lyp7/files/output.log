/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
tokenizer_config.json: 100% 110/110 [00:00<00:00, 230kB/s]
vocab.txt: 100% 15.7k/15.7k [00:00<00:00, 28.1MB/s]
config.json: 100% 478/478 [00:00<00:00, 1.13MB/s]

pytorch_model.bin: 100% 359M/359M [00:02<00:00, 167MB/s]
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m   [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type                  [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0 â”‚ bert                        â”‚ BertModel             â”‚ 89.1 M â”‚
â”‚ 1 â”‚ classifiers                 â”‚ ModuleList            â”‚ 12.6 M â”‚
â”‚ 2 â”‚ hidden_layer                â”‚ ModuleList            â”‚ 16.4 K â”‚
â”‚ 3 â”‚ sigmoid                     â”‚ Sigmoid               â”‚      0 â”‚
â”‚ 4 â”‚ criterion                   â”‚ Focal_MultiLabel_Loss â”‚      0 â”‚
â”‚ 5 â”‚ metrics                     â”‚ MetricCollection      â”‚      0 â”‚
â”‚ 6 â”‚ metrics_per_label_accuracy  â”‚ MetricCollection      â”‚      0 â”‚
â”‚ 7 â”‚ metrics_per_label_precision â”‚ MetricCollection      â”‚      0 â”‚
â”‚ 8 â”‚ metrics_per_label_recall    â”‚ MetricCollection      â”‚      0 â”‚
â”‚ 9 â”‚ metrics_per_label_f1score   â”‚ MetricCollection      â”‚      0 â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 19.7 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 101 M
[1mTotal estimated model params size (MB)[22m: 406
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of
training batches (26) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a
lower value for log_every_n_steps if you want to see logs for the training epoch.
[37mEpoch 0/3 [39m [35mâ”â”[90mâ•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m2/26[39m [37m0:00:01 â€¢ 0:00:02[39m [37m23.46it/s[39m [37mv_num: lyp7 train/loss:     









                                                                        [37m0.173                       



[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”[39m [37m6/7  [39m [37m0:00:03 â€¢ 0:00:01[39m [37m1.36it/s
Epoch 0, global step 26: 'val_loss' reached 0.17329 (best 0.17329), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2023-12-20/05-32-24/wandb/run-20231220_053430-9293lyp7/files/checkpoints/epoch=0.ckpt' as top 1



[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”[39m [37m6/7  [39m [37m0:00:03 â€¢ 0:00:01[39m [37m1.29it/s
Epoch 1, global step 52: 'val_loss' reached 0.17325 (best 0.17325), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2023-12-20/05-32-24/wandb/run-20231220_053430-9293lyp7/files/checkpoints/epoch=1.ckpt' as top 1
KeyboardInterrupt, attempting graceful shutdown...
Epoch 2/3  [35mâ”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m6/26[39m [37m0:00:07 â€¢ 0:00:25[39m [37m0.82it/s[39m [37mv_num: lyp7 train/loss:     
                                                                        [37m0.173                       

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m           Test metric           [22mâ”ƒ[1m          DataLoader 0           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m     test/multilabelaccuracy     [39mâ”‚[35m          0.91650390625          [39mâ”‚
â”‚[36m     test/multilabelf1score      [39mâ”‚[35m       0.02261904813349247       [39mâ”‚
â”‚[36m test/multilabelmatthewscorrcoef [39mâ”‚[35m       0.2356875091791153        [39mâ”‚
â”‚[36m    test/multilabelprecision     [39mâ”‚[35m       0.04398148134350777       [39mâ”‚
â”‚[36m      test/multilabelrecall      [39mâ”‚[35m       0.01522435899823904       [39mâ”‚
â”‚[36m            test_loss            [39mâ”‚[35m       0.17321446537971497       [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m4/4[39m [37m0:00:01 â€¢ 0:00:00[39m [37m1.63it/s
[?25h