
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type             [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ bert                        â”‚ BertModel        â”‚ 89.1 M â”‚
â”‚ 1  â”‚ classifiers                 â”‚ ModuleList       â”‚ 12.6 M â”‚
â”‚ 2  â”‚ hidden_layer1               â”‚ ModuleList       â”‚  4.2 M â”‚
â”‚ 3  â”‚ hidden_layer2               â”‚ ModuleList       â”‚  4.1 K â”‚
â”‚ 4  â”‚ sigmoid                     â”‚ Sigmoid          â”‚      0 â”‚
â”‚ 5  â”‚ criterion                   â”‚ Focal_Loss       â”‚      0 â”‚
â”‚ 6  â”‚ metrics                     â”‚ MetricCollection â”‚      0 â”‚
â”‚ 7  â”‚ metrics_per_label_accuracy  â”‚ MetricCollection â”‚      0 â”‚
â”‚ 8  â”‚ metrics_per_label_precision â”‚ MetricCollection â”‚      0 â”‚
â”‚ 9  â”‚ metrics_per_label_recall    â”‚ MetricCollection â”‚      0 â”‚
â”‚ 10 â”‚ metrics_per_label_f1score   â”‚ MetricCollection â”‚      0 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 23.9 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 105 M
[1mTotal estimated model params size (MB)[22m: 423
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of
training batches (46) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a
lower value for log_every_n_steps if you want to see logs for the training epoch.
[37mEpoch 0/3 [39m [35mâ”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m7/46[39m [37m0:00:02 â€¢ 0:00:12[39m [37m3.40it/s[39m [37mv_num: gt8l train/loss:     




                                                                        [37m0.170                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”[39m [37m9/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m4.08it/s
Epoch 0, global step 46: 'val_loss' reached 0.16904 (best 0.16904), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2024-01-17/05-44-51/wandb/run-20240117_054452-2tb3gt8l/files/checkpoints/epoch=0.ckpt' as top 1
[37mEpoch 0/3 [39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:15 â€¢ 0:00:00[39m [37m2.93it/s[39m [37mv_num: gt8l train/loss:     





                                                                        [37m0.167                       

Epoch 1/3  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:16 â€¢ 0:00:00[39m [37m2.86it/s[39m [37mv_num: gt8l train/loss:     
                                                                        [37m0.167                       




                                                                        [37m0.166                       

Epoch 2/3  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:16 â€¢ 0:00:00[39m [37m2.86it/s[39m [37mv_num: gt8l train/loss:     
                                                                        [37m0.166                       




                                                                        [37m0.166                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m5/12 [39m [37m0:00:00 â€¢ 0:00:02[39m [37m4.85it/s
Epoch 3/3  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:16 â€¢ 0:00:00[39m [37m2.85it/s[39m [37mv_num: gt8l train/loss:     
                                                                        [37m0.166                       
Epoch 3, global step 184: 'val_loss' reached 0.16610 (best 0.16610), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2024-01-17/05-44-51/wandb/run-20240117_054452-2tb3gt8l/files/checkpoints/epoch=3.ckpt' as top 1
`Trainer.fit` stopped: `max_epochs=4` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m           Test metric           [22mâ”ƒ[1m          DataLoader 0           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m  test/accuracy_label_ã‚ã„ã•ã¤   [39mâ”‚[35m       0.9628483057022095        [39mâ”‚
â”‚[36m  test/accuracy_label_ã‚ã„ã¥ã¡   [39mâ”‚[35m       0.9504643678665161        [39mâ”‚
â”‚[36m   test/accuracy_label_ãã®ä»–    [39mâ”‚[35m       0.6996904015541077        [39mâ”‚
â”‚[36m   test/accuracy_label_ä¸åŒæ„    [39mâ”‚[35m       0.9504643678665161        [39mâ”‚
â”‚[36m    test/accuracy_label_åŒæ„     [39mâ”‚[35m       0.6842105388641357        [39mâ”‚
â”‚[36m    test/accuracy_label_æƒ³èµ·     [39mâ”‚[35m        0.99071204662323         [39mâ”‚
â”‚[36m    test/accuracy_label_æ„è¦‹     [39mâ”‚[35m       0.8668730854988098        [39mâ”‚
â”‚[36m    test/accuracy_label_æ„Ÿå¿ƒ     [39mâ”‚[35m       0.13003095984458923       [39mâ”‚
â”‚[36m    test/accuracy_label_ç´å¾—     [39mâ”‚[35m       0.6873065233230591        [39mâ”‚
â”‚[36m test/accuracy_label_ç¹°ã‚Šè¿”ã—å¿œâ€¦ [39mâ”‚[35m        0.702786386013031        [39mâ”‚
â”‚[36m test/accuracy_label_è€ƒãˆã¦ã„ã‚‹â€¦ [39mâ”‚[35m       0.9597523212432861        [39mâ”‚
â”‚[36m    test/accuracy_label_è£œå®Œ     [39mâ”‚[35m        0.826625406742096        [39mâ”‚
â”‚[36m  test/accuracy_label_è¨€ã„æ›ãˆ   [39mâ”‚[35m               1.0               [39mâ”‚
â”‚[36m    test/accuracy_label_è©•ä¾¡     [39mâ”‚[35m       0.5139318704605103        [39mâ”‚
â”‚[36m    test/accuracy_label_é©šã     [39mâ”‚[35m       0.8482972383499146        [39mâ”‚
â”‚[36m test/accuracy_label_é©šãã¨ã„ã¶â€¦ [39mâ”‚[35m       0.9969040155410767        [39mâ”‚
â”‚[36m   test/f1score_label_ã‚ã„ã•ã¤   [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m   test/f1score_label_ã‚ã„ã¥ã¡   [39mâ”‚[35m        0.97444087266922         [39mâ”‚
â”‚[36m    test/f1score_label_ãã®ä»–    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/f1score_label_ä¸åŒæ„    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_åŒæ„     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_æƒ³èµ·     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_æ„è¦‹     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_æ„Ÿå¿ƒ     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_ç´å¾—     [39mâ”‚[35m       0.4093567132949829        [39mâ”‚
â”‚[36m test/f1score_label_ç¹°ã‚Šè¿”ã—å¿œç­” [39mâ”‚[35m       0.8048780560493469        [39mâ”‚
â”‚[36m test/f1score_label_è€ƒãˆã¦ã„ã‚‹ â€¦ [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_è£œå®Œ     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m   test/f1score_label_è¨€ã„æ›ãˆ   [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_è©•ä¾¡     [39mâ”‚[35m       0.5722070932388306        [39mâ”‚
â”‚[36m     test/f1score_label_é©šã     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/f1score_label_é©šãã¨ã„ã¶ â€¦ [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/multilabelaccuracy     [39mâ”‚[35m       0.7981811165809631        [39mâ”‚
â”‚[36m     test/multilabelf1score      [39mâ”‚[35m       0.17255517840385437       [39mâ”‚
â”‚[36m test/multilabelmatthewscorrcoef [39mâ”‚[35m       0.4466789960861206        [39mâ”‚
â”‚[36m    test/multilabelprecision     [39mâ”‚[35m       0.1685509979724884        [39mâ”‚
â”‚[36m      test/multilabelrecall      [39mâ”‚[35m       0.1969275027513504        [39mâ”‚
â”‚[36m  test/presicion_label_ã‚ã„ã•ã¤  [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m  test/presicion_label_ã‚ã„ã¥ã¡  [39mâ”‚[35m       0.9561128616333008        [39mâ”‚
â”‚[36m   test/presicion_label_ãã®ä»–   [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m   test/presicion_label_ä¸åŒæ„   [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_åŒæ„    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_æƒ³èµ·    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_æ„è¦‹    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_æ„Ÿå¿ƒ    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_ç´å¾—    [39mâ”‚[35m       0.6363636255264282        [39mâ”‚
â”‚[36m test/presicion_label_ç¹°ã‚Šè¿”ã— â€¦ [39mâ”‚[35m       0.6757678985595703        [39mâ”‚
â”‚[36m test/presicion_label_è€ƒãˆã¦ã„ â€¦ [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_è£œå®Œ    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m  test/presicion_label_è¨€ã„æ›ãˆ  [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_è©•ä¾¡    [39mâ”‚[35m       0.4285714328289032        [39mâ”‚
â”‚[36m    test/presicion_label_é©šã    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/presicion_label_é©šãã¨ã„ â€¦ [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m   test/recall_label_ã‚ã„ã•ã¤    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m   test/recall_label_ã‚ã„ã¥ã¡    [39mâ”‚[35m       0.9934853315353394        [39mâ”‚
â”‚[36m    test/recall_label_ãã®ä»–     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/recall_label_ä¸åŒæ„     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_åŒæ„      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_æƒ³èµ·      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_æ„è¦‹      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_æ„Ÿå¿ƒ      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_ç´å¾—      [39mâ”‚[35m       0.3017241358757019        [39mâ”‚
â”‚[36m test/recall_label_ç¹°ã‚Šè¿”ã—å¿œç­”  [39mâ”‚[35m       0.9949748516082764        [39mâ”‚
â”‚[36m test/recall_label_è€ƒãˆã¦ã„ã‚‹æœ€â€¦ [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_è£œå®Œ      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m   test/recall_label_è¨€ã„æ›ãˆ    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_è©•ä¾¡      [39mâ”‚[35m       0.8606557250022888        [39mâ”‚
â”‚[36m     test/recall_label_é©šã      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/recall_label_é©šãã¨ã„ã¶ã‹â€¦ [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m            test_loss            [39mâ”‚[35m       0.16564153134822845       [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m11/11[39m [37m0:00:02 â€¢ 0:00:00[39m [37m3.98it/s
[?25h