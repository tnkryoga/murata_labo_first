
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m    [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type             [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0  â”‚ bert                        â”‚ BertModel        â”‚ 89.1 M â”‚
â”‚ 1  â”‚ classifiers                 â”‚ ModuleList       â”‚  6.3 M â”‚
â”‚ 2  â”‚ hidden_layer1               â”‚ ModuleList       â”‚  2.1 M â”‚
â”‚ 3  â”‚ hidden_layer2               â”‚ ModuleList       â”‚  2.1 K â”‚
â”‚ 4  â”‚ sigmoid                     â”‚ Sigmoid          â”‚      0 â”‚
â”‚ 5  â”‚ criterion                   â”‚ Focal_Loss       â”‚      0 â”‚
â”‚ 6  â”‚ metrics                     â”‚ MetricCollection â”‚      0 â”‚
â”‚ 7  â”‚ metrics_per_label_accuracy  â”‚ MetricCollection â”‚      0 â”‚
â”‚ 8  â”‚ metrics_per_label_precision â”‚ MetricCollection â”‚      0 â”‚
â”‚ 9  â”‚ metrics_per_label_recall    â”‚ MetricCollection â”‚      0 â”‚
â”‚ 10 â”‚ metrics_per_label_f1score   â”‚ MetricCollection â”‚      0 â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 15.5 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 97.5 M
[1mTotal estimated model params size (MB)[22m: 390
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of
training batches (46) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a
lower value for log_every_n_steps if you want to see logs for the training epoch.
[37mEpoch 0/3 [39m [35mâ”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m3/46[39m [37m0:00:00 â€¢ 0:00:08[39m [37m5.38it/s[39m [37mv_num: aqql train/loss:     







                                                                        [37m0.160                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”[39m [37m11/12[39m [37m0:00:02 â€¢ 0:00:01[39m [37m4.44it/s
[37mEpoch 0/3 [39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:15 â€¢ 0:00:00[39m [37m2.95it/s[39m [37mv_num: aqql train/loss:     







                                                                        [37m0.155                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m6/12 [39m [37m0:00:00 â€¢ 0:00:01[39m [37m6.02it/s
Epoch 1, global step 92: 'val_loss' reached 0.15150 (best 0.15150), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2024-01-17/03-10-44/wandb/run-20240117_031045-81coaqql/files/checkpoints/epoch=1.ckpt' as top 1
Epoch 1/3  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:16 â€¢ 0:00:00[39m [37m2.87it/s[39m [37mv_num: aqql train/loss:     






                                                                        [37m0.155                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”[39m [37m7/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m5.37it/s
Epoch 2, global step 138: 'val_loss' reached 0.15059 (best 0.15059), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2024-01-17/03-10-44/wandb/run-20240117_031045-81coaqql/files/checkpoints/epoch=2.ckpt' as top 1
Epoch 2/3  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:16 â€¢ 0:00:00[39m [37m2.87it/s[39m [37mv_num: aqql train/loss:     








                                                                        [37m0.151                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”[39m [37m7/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m5.32it/s
Epoch 3, global step 184: 'val_loss' reached 0.15017 (best 0.15017), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp5/outputs/2024-01-17/03-10-44/wandb/run-20240117_031045-81coaqql/files/checkpoints/epoch=3.ckpt' as top 1
Epoch 3/3  [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m46/46[39m [37m0:00:16 â€¢ 0:00:00[39m [37m2.86it/s[39m [37mv_num: aqql train/loss:     
                                                                        [37m0.151                       
`Trainer.fit` stopped: `max_epochs=4` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m           Test metric           [22mâ”ƒ[1m          DataLoader 0           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m  test/accuracy_label_ã‚ã„ã¥ã¡   [39mâ”‚[35m       0.9503105878829956        [39mâ”‚
â”‚[36m    test/accuracy_label_åŒæ„     [39mâ”‚[35m       0.6801242232322693        [39mâ”‚
â”‚[36m    test/accuracy_label_æ„Ÿå¿ƒ     [39mâ”‚[35m       0.8664596080780029        [39mâ”‚
â”‚[36m    test/accuracy_label_ç´å¾—     [39mâ”‚[35m       0.6397515535354614        [39mâ”‚
â”‚[36m test/accuracy_label_ç¹°ã‚Šè¿”ã—å¿œâ€¦ [39mâ”‚[35m       0.7080745100975037        [39mâ”‚
â”‚[36m  test/accuracy_label_è¨€ã„æ›ãˆ   [39mâ”‚[35m       0.5062111616134644        [39mâ”‚
â”‚[36m    test/accuracy_label_è©•ä¾¡     [39mâ”‚[35m       0.5279502868652344        [39mâ”‚
â”‚[36m    test/accuracy_label_é©šã     [39mâ”‚[35m       0.8540372848510742        [39mâ”‚
â”‚[36m   test/f1score_label_ã‚ã„ã¥ã¡   [39mâ”‚[35m       0.9743589758872986        [39mâ”‚
â”‚[36m     test/f1score_label_åŒæ„     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_æ„Ÿå¿ƒ     [39mâ”‚[35m       0.9257340431213379        [39mâ”‚
â”‚[36m     test/f1score_label_ç´å¾—     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/f1score_label_ç¹°ã‚Šè¿”ã—å¿œç­” [39mâ”‚[35m       0.8057851195335388        [39mâ”‚
â”‚[36m   test/f1score_label_è¨€ã„æ›ãˆ   [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_è©•ä¾¡     [39mâ”‚[35m       0.5657142996788025        [39mâ”‚
â”‚[36m     test/f1score_label_é©šã     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/multilabelaccuracy     [39mâ”‚[35m       0.7166149020195007        [39mâ”‚
â”‚[36m     test/multilabelf1score      [39mâ”‚[35m        0.408949077129364        [39mâ”‚
â”‚[36m test/multilabelmatthewscorrcoef [39mâ”‚[35m       0.44065600633621216       [39mâ”‚
â”‚[36m    test/multilabelprecision     [39mâ”‚[35m       0.37104058265686035       [39mâ”‚
â”‚[36m      test/multilabelrecall      [39mâ”‚[35m       0.4683663249015808        [39mâ”‚
â”‚[36m  test/presicion_label_ã‚ã„ã¥ã¡  [39mâ”‚[35m        0.955974817276001        [39mâ”‚
â”‚[36m    test/presicion_label_åŒæ„    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_æ„Ÿå¿ƒ    [39mâ”‚[35m       0.8963210582733154        [39mâ”‚
â”‚[36m    test/presicion_label_ç´å¾—    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/presicion_label_ç¹°ã‚Šè¿”ã— â€¦ [39mâ”‚[35m       0.6818181872367859        [39mâ”‚
â”‚[36m  test/presicion_label_è¨€ã„æ›ãˆ  [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_è©•ä¾¡    [39mâ”‚[35m       0.43421053886413574       [39mâ”‚
â”‚[36m    test/presicion_label_é©šã    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m   test/recall_label_ã‚ã„ã¥ã¡    [39mâ”‚[35m       0.9934640526771545        [39mâ”‚
â”‚[36m     test/recall_label_åŒæ„      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_æ„Ÿå¿ƒ      [39mâ”‚[35m       0.9571428298950195        [39mâ”‚
â”‚[36m     test/recall_label_ç´å¾—      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/recall_label_ç¹°ã‚Šè¿”ã—å¿œç­”  [39mâ”‚[35m       0.9848484992980957        [39mâ”‚
â”‚[36m   test/recall_label_è¨€ã„æ›ãˆ    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_è©•ä¾¡      [39mâ”‚[35m        0.811475396156311        [39mâ”‚
â”‚[36m     test/recall_label_é©šã      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m            test_loss            [39mâ”‚[35m       0.15000884234905243       [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m11/11[39m [37m0:00:02 â€¢ 0:00:00[39m [37m4.31it/s
[?25h