
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loggers/wandb.py:389: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ[1m   [22mâ”ƒ[1m Name                        [22mâ”ƒ[1m Type                 [22mâ”ƒ[1m Params [22mâ”ƒ
â”¡â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ 0 â”‚ bert                        â”‚ BertModel            â”‚ 89.1 M â”‚
â”‚ 1 â”‚ classifiers                 â”‚ ModuleList           â”‚  6.3 M â”‚
â”‚ 2 â”‚ hidden_layer1               â”‚ ModuleList           â”‚  8.2 K â”‚
â”‚ 3 â”‚ sigmoid                     â”‚ Sigmoid              â”‚      0 â”‚
â”‚ 4 â”‚ criterion                   â”‚ Dice_MultiLabel_Loss â”‚      0 â”‚
â”‚ 5 â”‚ metrics                     â”‚ MetricCollection     â”‚      0 â”‚
â”‚ 6 â”‚ metrics_per_label_accuracy  â”‚ MetricCollection     â”‚      0 â”‚
â”‚ 7 â”‚ metrics_per_label_precision â”‚ MetricCollection     â”‚      0 â”‚
â”‚ 8 â”‚ metrics_per_label_recall    â”‚ MetricCollection     â”‚      0 â”‚
â”‚ 9 â”‚ metrics_per_label_f1score   â”‚ MetricCollection     â”‚      0 â”‚
â””â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[1mTrainable params[22m: 13.4 M
[1mNon-trainable params[22m: 82.0 M
[1mTotal params[22m: 95.4 M
[1mTotal estimated model params size (MB)[22m: 381
/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:293: The number of
training batches (46) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a
lower value for log_every_n_steps if you want to see logs for the training epoch.
[37mEpoch 0/3 [39m [35mâ”â”[90mâ•ºâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m4/46[39m [37m0:00:01 â€¢ 0:00:10[39m [37m4.22it/s[39m [37mv_num: s9e1 train/loss:     







                                                                        [37m0.518                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”[39m [37m11/12[39m [37m0:00:02 â€¢ 0:00:01[39m [37m4.44it/s









                                                                        [37m0.515                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•¸[90mâ”â”â”â”â”â”â”â”â”â”â”[39m [37m7/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m5.35it/s








                                                                        [37m0.492                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”[39m [37m8/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m4.95it/s








                                                                        [37m0.506                       

[37mValidation[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[90mâ•ºâ”â”â”â”â”â”â”â”[39m [37m8/12 [39m [37m0:00:01 â€¢ 0:00:01[39m [37m4.95it/s
Epoch 3, global step 184: 'val_loss' reached 0.49116 (best 0.49116), saving model to '/content/drive/MyDrive/murata_labo_exp/murata_labo_exp_src/exp6/outputs/2024-01-17/02-28-26/wandb/run-20240117_022827-l0h8s9e1/files/checkpoints/epoch=3.ckpt' as top 1
`Trainer.fit` stopped: `max_epochs=4` reached.
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ[1m           Test metric           [22mâ”ƒ[1m          DataLoader 0           [22mâ”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚[36m  test/accuracy_label_ã‚ã„ã¥ã¡   [39mâ”‚[35m       0.9534161686897278        [39mâ”‚
â”‚[36m    test/accuracy_label_åŒæ„     [39mâ”‚[35m       0.6832298040390015        [39mâ”‚
â”‚[36m    test/accuracy_label_æ„Ÿå¿ƒ     [39mâ”‚[35m       0.8757764101028442        [39mâ”‚
â”‚[36m    test/accuracy_label_ç´å¾—     [39mâ”‚[35m       0.6397515535354614        [39mâ”‚
â”‚[36m test/accuracy_label_ç¹°ã‚Šè¿”ã—å¿œâ€¦ [39mâ”‚[35m       0.7236024737358093        [39mâ”‚
â”‚[36m  test/accuracy_label_è¨€ã„æ›ãˆ   [39mâ”‚[35m       0.5403726696968079        [39mâ”‚
â”‚[36m    test/accuracy_label_è©•ä¾¡     [39mâ”‚[35m       0.6211180090904236        [39mâ”‚
â”‚[36m    test/accuracy_label_é©šã     [39mâ”‚[35m       0.8198757767677307        [39mâ”‚
â”‚[36m   test/f1score_label_ã‚ã„ã¥ã¡   [39mâ”‚[35m       0.9760000109672546        [39mâ”‚
â”‚[36m     test/f1score_label_åŒæ„     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_æ„Ÿå¿ƒ     [39mâ”‚[35m       0.9331103563308716        [39mâ”‚
â”‚[36m     test/f1score_label_ç´å¾—     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/f1score_label_ç¹°ã‚Šè¿”ã—å¿œç­” [39mâ”‚[35m       0.8134171962738037        [39mâ”‚
â”‚[36m   test/f1score_label_è¨€ã„æ›ãˆ   [39mâ”‚[35m       0.6605504751205444        [39mâ”‚
â”‚[36m     test/f1score_label_è©•ä¾¡     [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/f1score_label_é©šã     [39mâ”‚[35m       0.41999998688697815       [39mâ”‚
â”‚[36m     test/multilabelaccuracy     [39mâ”‚[35m       0.7321428656578064        [39mâ”‚
â”‚[36m     test/multilabelf1score      [39mâ”‚[35m       0.47538474202156067       [39mâ”‚
â”‚[36m test/multilabelmatthewscorrcoef [39mâ”‚[35m       0.46584439277648926       [39mâ”‚
â”‚[36m    test/multilabelprecision     [39mâ”‚[35m       0.4306117296218872        [39mâ”‚
â”‚[36m      test/multilabelrecall      [39mâ”‚[35m       0.5406784415245056        [39mâ”‚
â”‚[36m  test/presicion_label_ã‚ã„ã¥ã¡  [39mâ”‚[35m       0.9561128616333008        [39mâ”‚
â”‚[36m    test/presicion_label_åŒæ„    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_æ„Ÿå¿ƒ    [39mâ”‚[35m       0.8773584961891174        [39mâ”‚
â”‚[36m    test/presicion_label_ç´å¾—    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/presicion_label_ç¹°ã‚Šè¿”ã— â€¦ [39mâ”‚[35m       0.6953405141830444        [39mâ”‚
â”‚[36m  test/presicion_label_è¨€ã„æ›ãˆ  [39mâ”‚[35m       0.5198556184768677        [39mâ”‚
â”‚[36m    test/presicion_label_è©•ä¾¡    [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m    test/presicion_label_é©šã    [39mâ”‚[35m       0.3962264060974121        [39mâ”‚
â”‚[36m   test/recall_label_ã‚ã„ã¥ã¡    [39mâ”‚[35m       0.9967319965362549        [39mâ”‚
â”‚[36m     test/recall_label_åŒæ„      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_æ„Ÿå¿ƒ      [39mâ”‚[35m       0.9964285492897034        [39mâ”‚
â”‚[36m     test/recall_label_ç´å¾—      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m test/recall_label_ç¹°ã‚Šè¿”ã—å¿œç­”  [39mâ”‚[35m       0.9797979593276978        [39mâ”‚
â”‚[36m   test/recall_label_è¨€ã„æ›ãˆ    [39mâ”‚[35m       0.9056603908538818        [39mâ”‚
â”‚[36m     test/recall_label_è©•ä¾¡      [39mâ”‚[35m               0.0               [39mâ”‚
â”‚[36m     test/recall_label_é©šã      [39mâ”‚[35m       0.44680851697921753       [39mâ”‚
â”‚[36m            test_loss            [39mâ”‚[35m       0.4897921681404114        [39mâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
[37mTesting[39m [35mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”[39m [37m11/11[39m [37m0:00:02 â€¢ 0:00:00[39m [37m4.37it/s
[?25h